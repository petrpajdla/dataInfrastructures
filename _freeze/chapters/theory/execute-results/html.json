{
  "hash": "ee408a1d44a75091b4f8b3af9fc52807",
  "result": {
    "markdown": "# Theory and method {#sec-theory}\n\n:::{.callout-note}\n\n## @sec-theory introduces: {.unnumbered}\n\n- Definitions for fundamental concepts I am building upon further in the text.\n- An overview of theoretical approaches the work is determined and shaped by.\n- A discussion of archaeological research as theory- and/or data-driven.\n- A commentary on data from the theoretical points presented earlier.\n\n:::\n\n\n## Definitions and terminology {#sec-terms}\n\nThis section presents a discussion of how I (and others) understand **data** and **data infrastructures**.\nData are a corner stone of this work and looking closely at how scholars, policy makers, and various other stakeholders define them is crucial for further understanding what is possible and what is not in the process of knowledge building.\n\n### Data {#sec-terms-data}\n\nIn the current *information age*, word *data*[^1] is almost omnipresent and it became such a generic term that it is somewhat challenging to define.\nMost of the definitions understand data as building blocks of *information* [e.g. @kitchin2022, 4].\nThese pieces of information are percieved as pre-factual and pre-analytical.\nThat is, in contrast to facts, false data are data nonetheless, disproven facts are no longer facts [@rosenberg2013, 17-18].\nThus data are understood as incontrovertible and non-deconstructibe units.\nThese assumptions migh lead to an impression that data exist in the outside world as entities or phenomena independent of the one observing them.\nAnd this is indeed one way to comprehend data, as *'things given'* that just need to be discoverd [cf. @huggett2020a].\nThis inductive explanation of data brings in itself a danger that the process of discovering the data is viewed as an atheoretical endeavour.\n\n[^1]: In this text, I adhere to the current scholarly convention as noted by @kitchin2022 [xvii], i.e. using term *data* in the plural form, with a singular form of *datum*.\n\nOn the contrary, data understood as *'things made'* are created at the moment when they are captured by observation, measurement, or derived from other data.\nThis implies theory-laden creative process of data generation, recording, etc.\nIn this case, it is clear that the one creating or recording the data does that based on the experience, objective and knowledge he/she has.\nThe whole process of data recording, creation, or capture is thus discursively framed and technically mediated [cf. @kitchin2022, 4-15; @huggett2020a].\nAs Kitchin notes, what we label as data are in fact *capta*, i.e. *'things taken'*.\n\n@ruppert2017 voice the idea that the practice of data production does not happen through unstructured social (and/or political) practices, but through structured and structuring fields that add to configurations of power and knowledge.\nIn this section we went from understanding *data* as ubiquitous phenomena that are waiting out there to be discovered to *capta* that are actively and creatively made, recorded, generated etc. by a theory- and agenda-laden researcher.\nWhat more, the practice of data production is recognized as being shaped by and contributing to structure of power and knowledge.\nWhat data are recorded and how they are structured has consequences as to what can be later devised, i.e. what knowlege can be generated.\n\n<!--\n[@ruppert2017]:\n\"(...) the production of data is a social and often political practice that mobilizes agents who are not only objects of data (about whom data is produced) but that they are also subjects of data (those whose engagement drives how data is produced). Our question thus shifts to social practices and agents. Data does not happen through unstructured social practices but through structured and structuring fields in and through which various agents and their interests generate forms of expertise, interpretation, concepts, and methods that collectively function as fields of power and knowledge.\"\n\ncited in [@kitchin2022]:\n\"The production of data is a social practice, conducted through structured and structuring fields (e.g. methods, concepts, expertise, institutions) that are shaped by and contribute to configurations of power and knowledge.\"\n-->\n\nTalking about how chosen strategies in data recording and generation may influence the knowledge generated further along the way an idea of good and bad data might come to mind.\nBad data, like false data, do not exist.\nData can be useless, but their value is probably more determined by the current goal in mind.\nNevertheless, there are some signs of good-quality data as cited[^2] by @kitchin2022 [4]:\n\n- they are discreet and intelligible, i.e. each datum is individual, separate and separable, and clearly defined;\n- they are aggregative, that is they can be built into sets;\n- they have associated metadata (data about data);\n- they can be linked to other datasets to provide insights not available from a single dataset.\n\n[^2]: Author's note: Kitchin cites @rosenberg2013, but I was not able to locate this part in Rosenberg's paper, which is primarily focused on the history of the term *data* in English language, not the quality of data.\n\n<!-- \"(...) databases are designed and build to hold certain kinds of data and enable certain kinds of analysis, and how they are structured has profound consequences as to what queries and analysis can be performed.\" [@ruppert2012] -->\n\n### Infrastructures {#sec-terms-infra}\n\nAlthough *infrastructures* became quite a buzzword in recent years both among the policy makers and researchers, it is rather difficult to define what an infrastructure actually is.\nMany slightly different variations of more-less the same name and concept are circulating in official documents, various reports, research articles etc.\nThus, we encounter terms such as **research infrastructures**, large research infrastructures, open science infrastrucutres, **data infrastructures**, and perhaps more, even though most of their definitions are variations of the very same concept.\n\n@hallonsten2020 maps the field of European (research) infrastructures and identifies the principal problem as the difficulty to come up with a single definition that would fit all of those who are considered to be (or consider themselves to be) an *infrastructure*.\n@hallonsten2020 [630] concludes that:\n\n> *(...) \"while a politically viable definition seems to be either already in place (...) or unneeded, an analytically workable definition is out of reach unless the scope is limited and the aim of the definition is made more precise.\"*\n\nIn the next paragraphs, we look at several of the *political* definitions of research infrastructures and later we focus on an *analytical* definition of data infrastructures.\n\n#### Political definitions\n\nIn the European Union, research infrastructures are currently defined in the Article 2(1) of EU Regulation No 2021/695 establishing Horizon Europe [-@horizon] as facilities providing resources  and services for the research communities in their respective fields. These include:\n\n- human resources, major scientific equipment or sets of instruments;\n- collections, archives or scientific data, i.e. knowledge-related facilities;\n- computing systems and communication networks;\n- any other research and innovation infrastructure of a unique nature open to external users.\n\nThe *Regulation* also states that infrastructures may be used beyond research, i.e. for education, public services etc.\nThis broad definition given by the European Union covers almost any kind of an infrastructure.\nIn the legal framework of the Czech Republic, given by Act No 130/2002 Coll. on the Support of Research, Experimental Development and Innovation [-@zakon130], Article 2(2), *large research infrastructure* is defined as follow [english translation from Roadmap of Large Research Infrastructures -@roadmap2019]:\n\n> *\"(...) a facility necessary for conducting comprehensive research and development with high financial and technology demands, approved by the Government and established to be also used by other research organisations.\"*\n\nThis political definition is rather an opportunistic one in demanding that the infrastructure is approved by the Czech government and has high financial and technology demands.\nLastly, the UNESCO Open Science Recommendation [-@unesco2021] adds to the research infrastructures a strong element of open science, addressing them as *open science infrastructures*.\n\nTo conclude, the political definitions of research infrastructures are mostly broad enough to fit any kind of a facility, that is deemed appropriate.\nThis point is highlighted especially in the Czech definition, where an approval of the Government is required.\nIn general, there is an emphasis on provision of services (etc.) to various stakeholder communities and cooperation.\nIn the EU Regulation, a subset of a larger field of infrastructures is labeled *knowledge-related facilities*, it is exactly this part that is discussed here as *data infrastructures*.\n\n#### Data infrastructures\n\n@kitchin2022 [47-48] builds up the definition of data infrastructures by comparing them to *data holdings* and *data archives*.\n*Data holdings* are any data stored informally, presumably by an individual (scientist), without long-term preservation or sharing for reuse in mind.\nSuch data are inevitably lost when the researcher retires, dies (etc.), because proper metadata descriptions are missing and the data, although they might be organised in some way, lack  documentation and it is difficult, if not impossible, to reconstruct the context of the data.\nIn contrast, *data archives* are formal collections that are structured, curated and documented by appropriate metadata with plans for preservation, access and discoverability.\n\nThe role of an interconnected digital world is then highlighted in Kitchin's definition of a data infrastructure [@kitchin2022, 50]:\n\n> *\"A data infrastructure is a digital means for storing, sharing, connecting and consuming data holdings and archives across the internet.\"*\n\nData infrastructures are thus information systems, repositories, archives, databases etc. shared by multiple shareholder groups that are essential in supporting open science and research.\n\n\n## Overview of theoretical concepts {#sec-concepts}\n\nThis section aims at briefly introducing theoretical approaches this work is shaped by.\nAt first, digital humanities as an umbrella concept connecting the digital or computing world with the humanitites are introduced followed by discussion of digital, quantitative and computational archaeology.\nAnd lastly, spatial or landscape archaeology as a main concept framing this study is reviewed.\n\n### Digital humanities\n\n### Digital archaeology\n\n### Computational and quantitative archaeology\n\n### Spatial archaeology\n\n\n## Archaeology as theory- and data-driven\n\n::: {.callout-note}\n\n## Note\n\nThis section is partly based on the *Data-driven Archaeology. Are we there yet?* talk co-authored with Hana Kubelková and Petr Květina presented at the *Central European Theoretical Archaeology Group (CE TAG)* meeting focused on *Theoretical Approaches to Computational Archaeology* I coorganized with Michael Kempf, Jan Kolář and Jiří Macháček in 2021 at the Department of Archaeology and Museology, Faculty of Arts, Masaryk University.\n\n:::\n\nIn his vision for the future of archaeology, @kristiansen2014 [14] sees the opposition between theory and data disappear.\nHere we examine the percieved dichotomy between data- and theory-driven approaches.\nThe idea that scientific method and/or theory is dead was addressed by many, but I will start this discussion with a trending comment by @anderson2008.\n\nAnderson uses Boxes famous aphorism *\"(...) all models are wrong (...)\"* [@box1976, 792], later extended to *\"All models are wrong but some [models] are useful.\"* [@box1979, 202] and extends it to *\"All models are wrong, and increasingly you can succeed without them.\"* [@anderson2008].\n\n\n\n## Theorizing data\n\nDefining archaeological data, micro- to macro-scales;\n\nEarlier in this chapter it was explained that here, data is understood as *capta*, i.e. *things*, that are actively and creatively made, recorded, generated etc.\n\n  In this section we went from understanding data as ubiquitous phenomena that are waiting out there to be discovered to capta that are actively and creatively made, recorded, generated etc. by a theory- and agenda-laden researcher. What more, the practice of data production is recognized as being shaped by and contributing to structure of power and knowledge. What data are recorded and how they are structured has consequences as to what can be later devised, i.e. what knowlege can be generated.\n\n\n<!-- Here more less starts chapter Method -->\n\n## Assessing data infrastructures {#sec-quality}\n\nIn this section I define a framework for an assessment of the quality of data infrastructures.\nAs there are some signs of good-quality data (as cited from @kitchin2022 [4] in the @sec-terms-data), i.e. they are discreet and intelligible, aggregative, have associated metadata and can be linked to other datasets, by extension, good-quality data infrastructures allow data to be discreet and separable from other data, enable data aggregation, contain metadata and allow linking to other data sources.\nThis gives us a general idea about requirements for a data infrastrucutre, but is difficult to assess in practice.\nThese general ideas are concretized and further developed by the FAIR data principles [@wilkinson2016], which are aimed at enhancing the reusability of data holdings with an emphasis on the ability of machines to find and use the data.\nThe FAIR data principles are measurable what gives us an opportunity to assess how *FAIR* an infrastructure is.\n\n<!-- The CARE principles, on the other hand, are  -->\n\nFAIR data principles, i.e. findability, accessibility, interoperability and reusability, as originally defined by @wilkinson2016 [4], are as follows.\nTo be *findable*, data and metadata have globally unique and persistent identifiers; are described with rich metadata which include the identifier of the data they describe; and are registered or indexed in a searchable resource.\nTo be *accessible*, (meta)data are retrievable by the identifier using a standardized (open, free and universally implementable) communications protocol that allows for an authentication and authorization procedure; and metadata are accessible, even when the data are no longer available.\nTo be *interoperable*, (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation; contain vocabularies that follow FAIR principles; and include qualified references to other (meta)data.\nTo be *reusable*, meta(data) are richly described with a plurality of accurate and relevant attributes; are released with a clear and accessible data usage license; are associated with detailed provenance; and meet domain-relevant community standards.\n\n<!-- To be **Findable**:\n\n  - data and metadata have globally unique and persistent identifiers;\n  - data are described with rich metadata;\n  - metadata include the identifier of the data they describe;\n  - (meta)data are registered or indexed in a searchable resource.\n\nTo be **Accessible**:\n\n  - (meta)data are retrievable by the identifier using a standardized communications protocol;\n\n    - the protocol is open, free, and universally implementable;\n    - the protocol allows for an authentication and authorization procedure;\n\n  - metadata are accessible, even when the data are no longer available.\n\n- To be **Interoperable**:\n\n  - (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation;\n  - (meta)data use vocabularies that follow FAIR principles;\n  - (meta)data include qualified references to other (meta)data.\n\n- To be **Reusable**:\n\n  - meta(data) are richly described with a plurality of accurate and relevant attributes;\n\n    - (meta)data are released with a clear and accessible data usage license;\n    - (meta)data are associated with detailed provenance;\n    - (meta)data meet domain-relevant community standards. -->\n\nWith archaeology audiences in mind, the principles are further explained together with tips for implementations etc. by @hollander2019.\nHere I build up on @wilkinson2016 and @hollander2019 to come up with a set of formal, i.e. measurable and/or determinable criteria for assessment of data infrastructures.\nThis framework is then used to evaluate archaeology data infrastructures in the Czech Republic in @sec-data.\n\n### Assessment framework\n\n\n::: {.cell}\n\n:::\n\n\nAssessment criteria are grouped together according to the FAIR principle they relate to.\n@tbl-framework-f lists criteria for findability of resources.\nData should be easy to find by both humans and machines and well documented by metadata in order to be reusable by other researchers.\nTo be able to use the data object in any way, it must be possible to uniquely identify it, find it, and refer to it (F1).\nThis implies that an identifier of some sort, preferably persistent, i.e. immutable and long-lasting, is assigned to the resource (data and/or metadata).\nPersistent identifiers typically take form of DOIs, Handles, PURLs and URNs to name just a few examples[^3].\n\nFurthermore, it is convenient to be able to locate the resource (preferably on the internet) if the identifier, and possibly prefix of some sort, is known (F2).\nSince @marwick2018 explore the lack of data citation and reuse in archaeology and suggest a standard for data citation, one of the criteria is whether the infrastructure makes it easy to cite the resources it publishes (F3).\nAnother feature that enables findability of data is a rich metadata description (F4--F5).\n\n\n::: {#tbl-framework-f .cell tbl-cap='Framework for quality assessment of data infrastrastructres -- Findability'}\n::: {.cell-output-display}\n|ID   |Findability                                              |Value      |\n|:----|:--------------------------------------------------------|:----------|\n|F1.1 |Are there unique identifiers?                            |True/False |\n|F1.2 |Are the identifiers persistent?                          |True/False |\n|F1.3 |Are the identifiers in any standard form?                |True/False |\n|F2   |Is it possible to locate the resource by the identifier? |True/False |\n|F3   |Is it possible (and made easy) to cite:                  |-          |\n|F3.1 |- the data infrastructure,                               |True/False |\n|F3.2 |- its parts and/or                                       |True/False |\n|F3.3 |- individual resources?                                  |True/False |\n|F4.1 |Is the metadata scheme described, i.e. explicit?         |True/False |\n|F4.2 |Does the metadata scheme follow a standard?              |True/False |\n|F5   |Are the metadata searchable?                             |True/False |\n:::\n:::\n\n\n[^3]: Handles and DOIs (Digital Object Identifiers) are composed of a `prefix/suffix` and typically resolved at <https://doi.org/>.\nURNs (Uniform Resource Names), in form `urn:namespace:name`, are mostly used in the Semantic Web and are not resolvable, i.e. URNs do not have information about the location of the object.\nPURLs (Persistent Uniform Resource Locators) are an extension of URLs and are resolvable.\nURNs and (P)URLs are both subsets of URIs (Uniform Resource Identifiers).\nSee e.g. @ducharme2013 [21-23] for details.\n\nCriteria for accessibility are listed in @tbl-framework-a.\nAccessible data are retrievable under well-defined conditions using standardised protocols.\nCertification of a data infrastructure guarantees that its repository is trustworthy, the data are stored safely and will be available over a long period of time.\nCertifications may include [CoreTrustSeal](https://www.coretrustseal.org/), [nestor seal](https://www.langzeitarchivierung.de/) etc. (A1).\nBy a standardised exchange protocol (A2.1) a well-documented technology created and maintained by a recognized authority (e.g. World Wide Web Consortium, [W3C](https://www.w3.org/)) is meant.\nFor example [SPARQL](SPARQL) is a query language for semantic data created by W3C, [OAI-PMH](OAI-PMH), a Protocol for Metadata Harvesting, is created and maintained by the Open Archives Initiative etc.\nBy a standardised format (A2.2) a machine-readable format is meant, for instance [XML](https://www.w3.org/TR/xml11/), a W3C format for hierarchical data representation, [RDF](https://www.w3.org/TR/rdf-primer/), a W3C standard for semantic data, etc.\n\nFor (meta)data to be easily accessible, the policies for the access need to be clearly stated (A3), i.e. definitions of who can access what and when needs to be explicitly communicated, for example existence of differentiated user roles and/or embargo periods.\nThis gives both the users accessing the data clear instructions on how to access the objects they need, and the users depositing the data sets options to protect sensitive data etc.\nExistence of policies how to handle situations if a data object is no longer available (e.g. deleted, superseded etc.) and presence of metadata tombstones is a good practice how to  communicate that a data object existed, but does not anymore (A4).\n\n\n::: {#tbl-framework-a .cell tbl-cap='Framework for quality assessment of data infrastrastructres -- Accessibility'}\n::: {.cell-output-display}\n|ID   |Accessibility                                                 |Value      |\n|:----|:-------------------------------------------------------------|:----------|\n|A1   |Is the repository trustworthy?                                |True/False |\n|A2.1 |Are the (meta)data retrievable using a standardised protocol? |True/False |\n|A2.2 |Are the metadata in a standardised format?                    |True/False |\n|A3   |Is the access policy clearly stated?                          |True/False |\n|A3.1 |Are there embargo periods?                                    |True/False |\n|A3.2 |Are the access rights differentiated?                         |True/False |\n|A4   |Is the metadata available even after the data is not?         |True/False |\n:::\n:::\n\nInteroperability is the ability of the (meta)data to be easily combined with other data sets, @tbl-framework-i lists the interoperability criteria relevant to data infrastructures.\nMachine interoperability is closely related to the availability of APIs and their quality and human interoperability derives from the existence and extensiveness of documentation.\n\nTo enable interoperability, (meta)data model[^4] needs to be described clearly and accessibly (I1) and employed controlled vocabularies need to be explained and published, preferably following the FAIR principles (I2).\nExplanation of the given data model and vocabularies describing exact meanings embedded in the data are a prerequisites for building understanding by other people.\nFurthermore, well-documented (meta)data models allow creation of mappings between different metadata schemes and data infrastructures.\nSimilarly, the existence of machine actionable APIs (application programming interfaces, I4) that allow harvesting of (meta)data through standardised protocols and return responses in standardised formats (cf. A2) ensure machine interoperability.\n\n[^4]: The term *data model* is used here in the sense of how phenomena present, observed and/or measured in the real world are encoded in the data, what ratinale is behind the chosen abstraction process, and what is actually meant by the given wording.\n\n\n::: {#tbl-framework-i .cell tbl-cap='Framework for quality assessment of data infrastrastructres -- Interoperability'}\n::: {.cell-output-display}\n|ID   |Interoperability                                  |Value      |\n|:----|:-------------------------------------------------|:----------|\n|I1   |Is the (meta)data model explained and documented? |True/False |\n|I2.1 |Are the vocabularies published and/or well-known? |True/False |\n|I2.2 |Are the vocabularies FAIR?                        |True/False |\n|I3   |Are other metadata referenced properly?           |True/False |\n|I4.1 |Is there a machine-actionable API?                |True/False |\n|I4.2 |Is the API well documented?                       |True/False |\n:::\n:::\n\n\nBy reusability the process of making data ready for future processing and analysis is meant.\nThis is crucial for reproducibility of scientific research.\nData, repositories and infrastructures that are systematically documented by manuals, tutorials, guides, codebooks etc. and transparent about what they do and do not contain foster reuse, because researchers reusing the data have clear notion of what to expect from the data source (R1).\nReusability is also enhanced by using widely used and open source file formats (R2).\nIn the long run, long-term preservation (LTP) is a prerequisite for reusability, because if the file format in which the data is saved gets obsolete, it is often difficult to retrieve the original data, see @brin2013 for recommended file formats, online as *Guides to Good Practice* [-@archaeologydataservice].\n\nIntegrity of the (meta)data and existence of multiple versions of the given data objects is also important to consider, because if this information is not properly communicated, different versions of the data objects with identical identifiers might get mixed up (R3).\nThis closely relates to the provenance of the data, i.e. the documentation of the origin of the data object and record of any changes with a rationale behind these processes.\nKnowing why changes in the (meta)data happened, whether it was a correction of a previous mistake or something else, might be useful for data reuse in the future.\nLastly, releasing the (meta)data with proper license information, preferably under a standard data license, for instance a [Creative Commons Licence](https://creativecommons.org/), and any information on a rights holder is neccessary for future reuse because without this information, it is unclear what the terms of (meta)data use are.\n\n\n::: {#tbl-framework-r .cell tbl-cap='Framework for quality assessment of data infrastrastructres -- Reusability'}\n::: {.cell-output-display}\n|ID   |Reusability                                           |Value      |\n|:----|:-----------------------------------------------------|:----------|\n|R1   |Are there documentation, manuals, tutorials etc?      |True/False |\n|R2.1 |Are common file formats used?                         |True/False |\n|R2.2 |Are file formats suitable for long-term preservation? |True/False |\n|R3.1 |Is the (meta)data provenance documented?              |True/False |\n|R3.2 |Are there any version control mechanisms in place?    |True/False |\n|R4.1 |Are the rights holders and terms of use clear?        |True/False |\n|R4.2 |Are the resources released under a standard license?  |True/False |\n:::\n:::\n\nThe framework consists predominantly of qualities that are measurable and builds up on the FAIR data principles.\nCARE data principles, as defined by @carroll2020, were considered as well, but their goal is to increase the indigenous data sovereignity and self-determination by being people and purpose-oriented, while the FAIR data principles are primarily focused on the characteristics of the data.\nCARE data principles are put together to address imbalances of power in the knowledge societies and economies and protect indigenous and human rights.\nHence the extent to which a data infrastructure adheres to CARE data principles is difficult to determine and/or measure.\n\nThe framework for assessment of the quality of data infrastructures is used in @sec-data to evaluate the quality of archaeology data infrastructures in the Czech Republic.\n\n## Software\n\nMost of the things included here, if not all of them, were achieved using open-source software.\nLarge part of this endeavor is also documented in code.\nThis text was written in plain text with some basic markdown and quarto syntax for formatting, cross references, citations etc.\nAt some places there are R code blocks.\nThe text is processed into three outputs, a [website](https://petrpajdla.github.io/dataInfrastructures/) (HTML document), a [PDF](https://petrpajdla.github.io/dataInfrastructures/Archaeology-Data-Infrastructures.pdf) document and a [MS Word](https://petrpajdla.github.io/dataInfrastructures/Archaeology-Data-Infrastructures.docx) document using Quarto.\nThe plain text version, same as the rendered website, is hosted at [GitHub](https://github.com/petrpajdla/dataInfrastructures).\nThe text was mostly written in the Visual Code Studio, analysis were mostly performed using Rstudio or terminal.\nLibrary was organized using [Zotero]().\n\nRaster graphics were created and edited using [GIMP](), vector graphics using [Inkscape]().\nAll the GIS operations that required graphical user interface (GUI), or were more conveniently performed in a GUI, were done in [QGIS]().\n\nSome data were prepared, extracted or processed using basic GNU/Linux shell or SQL commands or scripts.\nData from [Wikidata]() was queried using SPARQL.\nAny analysis was mostly done in R, a language for statistical computing and graphics [@rcore].\nVarious packages were used, the most important packages are listed here, the complete list is in an Appendix\n\n\n### Reproduciblity\n\n\n## Chapter summary {.unnumbered}\n\n<!-- One paragraph summarising what is the chapter about. -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}