[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Archaeology Data Infrastructures",
    "section": "",
    "text": "Preface\n\n\n\n\n\n\nWarning\n\n\n\nThis is a website for the work-in-progress PhD thesis of mine. It is not intended to be read by anyone except me (and maybe few other people) yet. If you do flick through it anyway, consider yourself warned. It might be messy at some places and will definitely undergo serious rewriting.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis work can be read online at https://petrpajdla.github.io/dataInfrastructures/. The source repository is on GitHub at https://github.com/petrpajdla/dataInfrastructures/.\n\n\n\nThis document is created in an open-source Quarto scientific and technical publishing system. You might be asking why is it published and written like this even if it is not intended for any audiences except myself yet. I have no answer to this. One evening I simply decided to give Quarto publishing a try and set this whole thing up in less then an hour or so.\n\nNotes on writing\nThis note is written mostly for a future me, in case I need to set up the working environment again on a different machine and to serve as a memo if I forget how to continue.\nAs of November 2022, this is written on Archlabs GNU/Linux machine, mostly in Visual Studio Code editor and sometimes in RStudio. Changes are tracked with Git and a remote repository is on GitHub (see the note above), same as the rendered website. The rendered version of the manuscript is in the branch gh-pages. See a guide on how to set this up here.\nIn my point of view, there are numerous advantages to scientific writing in this manner over traditional Office-based approach. A non-exhaustive list of why to do scientific writing this way is below.\n\nPlain text Writing in plain text enhanced with a simple Markdown syntax and some Quarto elements is great because from one source document, a .pdf, .html, .docx (and probably more) document formats can be rendered using pandoc.\nVersion control Tracking changes using git is easily implemented when writing in a plain text. Keeping track of any changes in the manuscript is obviously crucial for any later revisions etc.\nSimple citation management Bibliography is organized using Zotero with Better BibTeX extension which is used to export (and keep updated) necessary collections in a parent folder of the manuscript as .bib files. My Zotero library is here. To format the citations, a citation style of the Journal of Computer Applications in Archaeology is used (.csl file was obtained here).\nEmbedded code Code blocks (and the associated results) can be easily embedded in the text. My language of choice is R. For more information on reproducibility see Marwick (2017) and Marwick, Boettiger and Mullen (2018).\nReproduciblity Using renv package makes reproducibility of the whole project less tedious than I would normally expect. Hints:\n\nuse renv::status() to check the status of the project,\nuse renv::install() (install.packages() is aliased to it as well) to install new packages,\nuse renv::snapshot() to update the lockfile,\nuse renv::restore() to restore the state of the project/dependencies recorded in the lock file\nuse renv::update() to updated the project.\n\n\n\nMarwick, B. 2017 Computational Reproducibility in Archaeological Research: Basic Principles and a Case Study of Their Implementation. Journal of Archaeological Method and Theory 24(2): 424–450. DOI: https://doi.org/10.1007/s10816-015-9272-9.\n\nMarwick, B, Boettiger, C and Mullen, L. 2018 Packaging Data Analytical Work Reproducibly Using R (and Friends). The American Statistician 72(1): 80–88. DOI: https://doi.org/10.1080/00031305.2017.1375986.\nSee https://rstudio.github.io/renv/index.html for more details, as well as this figure:\n\n\n\nBasic usage of renv\n\n\n\n\n\n\n\n\nIn-text citations\n\n\n\n\n\n@citekey -&gt; Author (year)\n-@citekey -&gt; (year)\n[@citekey] -&gt; (Author, year)\n@citekey [p. X] -&gt; Author (year, p. X)\n\n\n\n\n\n\n\n\n\nCrossrefs\n\n\n\n\n\n{#sec-label} -&gt; #sec-label\n{#fig-label} -&gt; #fig-label\ncrossref without numbering: -@sec-label, [Chapter -@sec-label]\n\n\n\n\n\nStats\nAs of February 11, 2024 there are roughly 21.7 pages (1800 characters per page) of text. Length of individual chapters is as follows:\n\nIntroduction: 2 pages\nTheory and Method: 15 pages\nData and materials: 4 pages\n\n\n\n     w     c ns                   f\n1  508  3551  2  chapters/intro.qmd\n2 3963 27385 15 chapters/theory.qmd\n3 1222  8089  4   chapters/data.qmd\n4 5693 39025 22               total",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Context",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-context",
    "href": "chapters/intro.html#sec-context",
    "title": "Introduction",
    "section": "",
    "text": "Archaeological heritage management in the Czech Republic\nHow archaeology, its finds, sites and data are managed in various countries is heavily influenced by given legal framework. In this section, issues specific to the case of the Czech Republic are shortly described to give a basic context for the study.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-questions",
    "href": "chapters/intro.html#sec-questions",
    "title": "Introduction",
    "section": "Research questions",
    "text": "Research questions",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/intro.html#sec-outline",
    "href": "chapters/intro.html#sec-outline",
    "title": "Introduction",
    "section": "Thesis outline",
    "text": "Thesis outline\n\nHere is a brief outline of the structure of the thesis. In 1  Theory and method, Theory, the foundation is given by defining basic terms, data, data infrastructures etc. Then, theoretical approaches the work spans from are discussed and the concept of data in archaeology theorized. The dichotomy between archaeology as data- and/or theory-driven science is debated.\n\n2  Data and materials, Data, introduces data sources that are used here. Understanding the data models employed in various data sources is vital for any subsequent steps taken in the analytical process. Special attention is thus given to analysing how reality and facts are represented by the data models of used sources. A data management plan (2.2 Data management) details how data is handled in this research.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/intro.html#summary",
    "href": "chapters/intro.html#summary",
    "title": "Introduction",
    "section": "Summary",
    "text": "Summary",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/theory.html",
    "href": "chapters/theory.html",
    "title": "1  Theory and method",
    "section": "",
    "text": "1.1 Definitions and terminology\nThis section presents a discussion of how I (and others) understand data and data infrastructures. Data are a corner stone of this work and looking closely at how scholars, policy makers, and various other stakeholders define data is crucial for further understanding of what is possible and what is not in the process of knowledge building.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/theory.html#sec-terms",
    "href": "chapters/theory.html#sec-terms",
    "title": "1  Theory and method",
    "section": "",
    "text": "1.1.1 Data\nIn the current information age, word data1 is almost omnipresent and it became such a generic term that almost everyone has some notion or idea of what data are. Most of the formal definitions understand data as building blocks of information (e.g. Kitchin 2022: 4). These pieces of information are percieved as pre-factual and pre-analytical. That is, in contrast to facts, false data are data nonetheless, disproven facts are no longer facts (Rosenberg 2013: 17–18). What more, data need to be analysed and interpreted to make a meaning. Data are furthermore understood as incontrovertible and non-deconstructible units. These assumptions migh lead to an impression that data exist in the outside world as entities or phenomena independent of the one observing them. And this is indeed one way to comprehend data, as ‘things given’ that just need to be discoverd (cf. Huggett 2020). This inductive explanation of data brings in itself a danger that the process of discovering the data is viewed as an atheoretical endeavour.\n1 In this text, I adhere to the current scholarly convention as noted by Kitchin (2022, xvii), i.e. using term data in the plural form, with a singular form of datum.On the contrary, if data are understood as ‘things made’ they are created at the moment when they are captured by observation, measurement, or derived from other data. This implies theory-laden creative process of data generation, recording, etc. In this case, it is clear that the one creating or recording the data does that based on the experience, objective and knowledge he/she has. The whole process of data recording, creation, or capture is thus discursively framed and technically mediated (Huggett 2020; cf. Kitchin 2022: 4–15). As Kitchin notes, what we nowadays label as data are in fact capta, i.e. ‘things taken’.\nRuppert, Isin and Bigo (2017) voice the idea that the practice of data production does not happen through unstructured social (and/or political) practices, but through structured and structuring processes that add to configurations of power and knowledge. Hence, I do not understand data as ubiquitous phenomena that are waiting out there to be discovered but as capta that are actively and creatively made, recorded, generated etc. by a theory- and agenda-laden researchers. What more, the practice of data production is shaped by and contributing to structure of power and knowledge, because what data are recorded and how they are structured has consequences as to what can be later devised, i.e. what knowlege can be generated.\n\n\nRuppert, E, Isin, E and Bigo, D. 2017 Data politics. Big Data & Society 4(2): 2053951717717749. DOI: https://doi.org/10.1177/2053951717717749.\n2 Author’s note: Kitchin cites Rosenberg (2013), but I was not able to locate this part in Rosenberg’s paper, which is primarily focused on the history of the term data in English language, not the quality of data.\nRosenberg, D. 2013 Data before the fact. In: Gitelman, L (ed.). ’Raw Data’ is an Oxymoron. Cambridge, MA: MIT Press. pp. 15–40.\nIf the chosen strategies in data recording and generation influence the knowledge generated further along the way, an idea of good and bad data comes to mind.  Bad data, like false data, do not exist. Data can be useless, but the value of data is determined by the current goal in mind, data deemed useless by one project can become useful on other occassion, perhaps previously unforeseen and unintended. Nevertheless, there are some signs of good-quality data as cited2 by Kitchin (2022: 4):\n\nthey are discreet and intelligible, i.e. each datum is individual, separate and separable, and clearly defined;\nthey are aggregative, that is they can be built into sets;\nthey have associated metadata (data about data);\nthey can be linked to other datasets to provide insights not available from a single dataset.\n\n\n\n\n1.1.2 Infrastructures\nAlthough infrastructures became quite a buzzword in recent years both among the policy makers and researchers, it is rather difficult to define what an infrastructure actually is. Many slightly different variations of more-less the same name and concept are circulating in official documents, various reports, research articles etc. Thus, we encounter terms such as research infrastructures, large research infrastructures, open science infrastrucutres, data infrastructures, and perhaps more, even though most of their definitions are variations of the very same concept.\nHallonsten (2020) maps the field of European (research) infrastructures and identifies the principal problem as the difficulty to come up with a single definition that would fit all of those who are considered to be (or consider themselves to be) an infrastructure. Hallonsten (2020: 630) concludes that:\n\nHallonsten, O. 2020 Research Infrastructures in Europe: The Hype and the Field. European Review 28(4): 617–635. DOI: https://doi.org/10.1017/S1062798720000095.\n\n(…) “while a politically viable definition seems to be either already in place (…) or unneeded, an analytically workable definition is out of reach unless the scope is limited and the aim of the definition is made more precise.”\n\nIn the next paragraphs, we look at several of the political definitions of research infrastructures and later we focus on an analytical definition of data infrastructures.\nPolitical definitions\nIn the European Union, research infrastructures are currently defined in the Article 2(1) of EU Regulation No 2021/695 establishing Horizon Europe (2021) as facilities providing resources and services for the research communities in their respective fields. These include:\n\nAnon. 2021 Regulation (EU) 2021/695 of the European Parliament and of the Council. 32021R0695.\n\nhuman resources, major scientific equipment or sets of instruments;\ncollections, archives or scientific data, i.e. knowledge-related facilities;\ncomputing systems and communication networks;\nany other research and innovation infrastructure of a unique nature open to external users.\n\nThe Regulation also states that infrastructures may be used beyond research, i.e. for education, public services etc. This broad definition given by the European Union covers almost any kind of an infrastructure. In the legal framework of the Czech Republic, given by Act No 130/2002 Coll. on the Support of Research, Experimental Development and Innovation (2002), Article 2(2), large research infrastructure is defined as follow (english translation from Roadmap of Large Research Infrastructures 2019):\n\nAnon. 2002 Act No 130/2002 Coll. (The Act on the Support of Research, Experimental Development and Innovation), as amended.\n\nAnon. 2019. Roadmap of Large Research Infrastructures of the Czech Republic for the years 2016-2022. Update 2019. Prague: Ministry of Education, Youth and Sports.\n\n“(…) a facility necessary for conducting comprehensive research and development with high financial and technology demands, approved by the Government and established to be also used by other research organisations.”\n\nThis political definition is rather an opportunistic one in demanding that the infrastructure is approved by the Czech government and has high financial and technology demands. Lastly, the UNESCO Open Science Recommendation (2021) adds to the research infrastructures a strong element of open science, addressing them as open science infrastructures.\n\nUNESCO. 2021 UNESCO Recommendation on Open Science.\nTo conclude, the political definitions of research infrastructures are mostly broad enough to fit any kind of a facility, that is deemed appropriate. This point is highlighted especially in the Czech definition, where an approval of the Government is required. In general, there is an emphasis on provision of services (etc.) to various stakeholder communities and cooperation. In the EU Regulation, a subset of a larger field of infrastructures is labeled knowledge-related facilities, it is exactly this part that is discussed here as data infrastructures.\nData infrastructures\nKitchin (2022: 47–48) builds up the definition of data infrastructures by comparing them to data holdings and data archives. Data holdings are any data stored informally, presumably by an individual (scientist), without long-term preservation or sharing for reuse in mind. Such data are inevitably lost when the researcher retires, dies (etc.), because proper metadata descriptions are missing and the data, although they might be organised in some way, lack documentation and it is difficult, if not impossible, to reconstruct the context of the data. In contrast, data archives are formal collections that are structured, curated and documented by appropriate metadata with plans for preservation, access and discoverability.\nThe role of an interconnected digital world is then highlighted in Kitchin’s definition of a data infrastructure (Kitchin 2022: 50):\n\n“A data infrastructure is a digital means for storing, sharing, connecting and consuming data holdings and archives across the internet.”\n\nData infrastructures are thus information systems, repositories, archives, databases etc. shared by multiple shareholder groups that are essential in supporting open science, research and in our case archaeological heritage management.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/theory.html#sec-concepts",
    "href": "chapters/theory.html#sec-concepts",
    "title": "1  Theory and method",
    "section": "1.2 Overview of theoretical concepts",
    "text": "1.2 Overview of theoretical concepts\nThis section aims at briefly introducing theoretical approaches this work is shaped by. At first, digital humanities as an umbrella concept connecting the digital and/or computing world with the humanitites are introduced followed by discussion of digital, quantitative and computational archaeology. And lastly, spatial archaeology as a main concept framing this study is reviewed.\nDigital humanities is now a fully developed interdisciplinary field that utilizes computational methods and digital tools to conduct research, analyze, and interpret humanities data and artefacts. Digital humanities does not create qualitatively new science, it enhances and extends the ways in which scholars in the humanities approach their research questions with extensive use of computational methods, statistics, geographic information systems, network analyses, text mining etc.\nArchaeology, with its strong interdisciplinary focus and early adoption of many innovations, positions itself somewhat aside from the digital humanities. The difference of archaeology might be given by its specific sources, ie. the material culture objects, which is distinct from many of digital humanities disciplines, which are predominantly based on textual sources. Fieldwork, physical excavations, handling of material culture and focus on physical preservation are processes that lead to archaelogy having apparently closer connections to some of natural sciences, like geology, than to other humanities text-centric disciplines, like history. On the other hand, there are many intersections between digital humanities and archaeology that speak for stronger inclusion of archaeology in this field.\nTODO: Describe why DH is relevant, brief intro on Digital, computational and quantitative archaeology, spatial archaeology",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/theory.html#archaeology-as-theory--and-data-driven",
    "href": "chapters/theory.html#archaeology-as-theory--and-data-driven",
    "title": "1  Theory and method",
    "section": "1.3 Archaeology as theory- and data-driven",
    "text": "1.3 Archaeology as theory- and data-driven\n\n\n\n\n\n\nNote\n\n\n\nThis section is partly based on the Data-driven Archaeology. Are we there yet? talk co-authored with Hana Kubelková and Petr Květina presented at the Central European Theoretical Archaeology Group (CE TAG) meeting focused on Theoretical Approaches to Computational Archaeology I coorganized with Michael Kempf, Jan Kolář and Jiří Macháček in 2021 at the Department of Archaeology and Museology, Faculty of Arts, Masaryk University.\n\n\nIn his vision for the future of archaeology, Kristiansen (2014: 14) sees the opposition between theory and data disappear. Here I examine the dichotomy between data- and theory-driven approaches in archaeology, because this work utilises large amounts of data and addressing its data-driven nature is important for methodological transparency and reproducibility, as well as understanding what does it mean in the first place. Abundance of data led to an idea that scientifc method and/or theory is obsolete. This idea was addressed by many, but I will start the discussion with a trending comment by Anderson (2008).\n\nAnderson, C. 2008 The End of Theory: The Data Deluge Makes the Scientific Method Obsolete. Wired.\n\nBox, GEP. 1976 Science and Statistics. Journal of the American Statistical Association 71(356): 791–799. DOI: https://doi.org/10.1080/01621459.1976.10480949.\n\nBox, GEP. 1979 Robustness in the Strategy of Scientific Model Building. In: Launer, RL and Wilkinson, GN (eds.). Robustness in Statistics. Academic Press. pp. 201–236. DOI: https://doi.org/10.1016/B978-0-12-438150-6.50018-2.\n3 Big data is a phrase often heard in archaeology to address large amounts of data. In fact, it is a technical term for a data defined by their large volume, velocity, variety, exhaustivity, resolution, etc. (Kitchin 2022: 61–74). For instance some geophysical, 3D, remote sensing, or archaeogenetic and similar data can fit under the definition of big data, but most of archaeological data, like databases of sites and assamblages etc. are not big data by definition, even though they might cover large spatial and/or temporal regions and consist of many records and variables.\nKitchin, R. 2022. The data revolution: A critical analysis of big data, open data & data infrastructures. 2nd ed. Los Angeles, California: SAGE Publications.\nAnderson uses Boxes famous aphorism “(…) all models are wrong (…)” (Box 1976: 792), later extended to “All models are wrong but some [models] are useful.” (Box 1979: 202) and extends it to “All models are wrong, and increasingly you can succeed without them.” (Anderson 2008). By this statement, the author means that scientific method as we know it, i.e. positing a research question based on previous knowledge and observation, formulating a testable and falsifiable hypothesis to address this question, and gathering data or conducting experiments in order to test the hypothesis, is superseded by accumulating large quantities of data (or big data3) and analyzing it for correlations is good enough, even better, than burdening yourself with building models first. Anderson simply proclaims that “correlation supersedes causation, and science can advance even without coherent models, unified theories, or really any mechanistic explanation at all”.\nBoth theory-driven and data-driven aspects are fundamentally rooted in archaeology. The theory-driven aspect of archaeology comes in a plurality of conceptual frameworks or paradigms, e.g. cultural history, cultural ecology, processual and post-processual archaeology etc. Theories in archaeology shape interpretive models that are created to make sense of the past embedded in material objects. They influence the decisions about the design of archaeological projects, like what aspects of archaeological record and data are deemed significant and worthy preserving or what sampling strategy is chosen.\nThe data-driven aspect of archaeology spans from the focus on material remains of past human activities. The collection, documentation and analysis of the data on artefacts, ecofacts, and other evidence etc. are central part of archaeological practice. The urge to meticulously document each and every detail of the excavated situation is driven by the non-repeatable nature of archaeological research. Together with the use of scientific techniques, such as aDNA analysis, radiocarbon dating etc. and various quantitative methods, GIS, and statistical techniques, an impression or fallacy of objectivity and practice devoid of presumptions or theory arises.\nTo summarise, theory-driven approach is a top-down process, where knowlege is created by testing models against reality, the data-driven approach is a bottom-up process, where knowledge is created by identifying patterns in large data sets (Maass et al. 2018). Theory and data driven approaches coexist in archaeology in relationship that does I do not see as a strictly binary opposition. Anderson’s comment challenges scientific method, emphasizing possibilities of vast data sets for uncovering patterns, yet the vast data sets, or big data, would not exist in archaeology without decisions driven by theory and models how to create them in one way or another in the first place.\n\nMaass, W, Parsons, J, Purao, S, Storey, VC and Woo, C. 2018 Data-Driven Meets Theory-Driven Research in the Era of Big Data: Opportunities and Challenges for Information Systems Research. Journal of the Association for Information Systems 1253–1273. DOI: https://doi.org/10.17705/1jais.00526.\nIn summary, the duality of approaches in archaeology creates an iterative dialogue, where theories guide the formulation of research questions and interpretation of phenomena, while data derived from fieldwork and analysis continually refine theories and models. In this sense, the opposition between theory and data is indeed disappearing, as Kristiansen suggests, and theory- and data-driven approachech permeate and intermingle one with the other, creating a dynamic and evolving discipline.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/theory.html#theorizing-archaeological-data",
    "href": "chapters/theory.html#theorizing-archaeological-data",
    "title": "1  Theory and method",
    "section": "1.4 Theorizing archaeological data",
    "text": "1.4 Theorizing archaeological data\nIn the previous section I discussed the interwining nature of archaeology as theory-driven and data-driven practice. Here I delve into the discussion of the heterogeneous nature of archaeological data. Even earlier in this chapter it was explained that here, data is understood as capta, i.e. it is actively and creatively made, recorded, generated etc. In this sense, also archaeological data is in fact archaeological capta, meaning that in my point of view, it is created the moment it is recorded, it does not exist on its own, an agent’s incentive is then a neccessary condition for the capta/data to originate.\nI will start this section by citing three authors dealing with the nature of archaeological data and use their critical comments on the problematic nature of archaeology data as a starting point for explaining how it is understood throughout this work:\n\n“(…) however dense it becomes, archaeological evidence will always remain patchy, with levels of uncertainty and variable expert opinions that are hugely challenging.” (Bevan 2015: 1477)\n\nBevan, A. 2015 The data deluge. Antiquity 89(348): 1473–1484. DOI: https://doi.org/10.15184/aqy.2015.102.\n\n\n“Archaeological data are shadowy in a number of senses. They are notoriously incomplete and fragmentary, and the sedimented layers of interpretive scaffolding on which archaeologists rely to constitute these data as evidence carry the risk that they will recognize only those data that conform to expectation.” (Wylie 2017: 1477)\n\nWylie, A. 2017 How Archaeological Evidence Bites Back: Strategies for Putting Old Data to Work in New Ways. Science, Technology, & Human Values 42(2): 203–225. DOI: https://doi.org/10.1177/0162243916671200.\n\n\n“Archaeological data is always incomplete, frequently unreliable, often replete with unknown unknowns (…)” (Huggett 2020: S8)\n\nHuggett, J. 2020 Is Big Digital Data Different? Towards a New Archaeological Paradigm. Journal of Field Archaeology 45: S8–S17. DOI: https://doi.org/10.1080/00934690.2020.1713281.\n\nThe citation from Bevan’s article could suggests that although abundance of archaeological evidence is accumulated over time, and especially in recent decades in vast amounts (data deluge), it is difficult, sic impossible, to draw conclusions about the past. On the contrary, the author acknowledges that “(…) at least in certain parts of the world, we cannot in all good conscience claim ‘we don’t yet have enough evidence’ or that we should ‘wait till the evidence is in’.” In a similar manner, Kristiansen (2014: 18) assumes that “After 40 years of contract archaeology, real historical knowledge about settlements and landscapes is possible.” However optimistic these claims sound, they are not without problems. The first one is expressed in Bevan’s citation, ie. the patchy nature of archaeological evidence and associated uncertainty levels. Although there is most certainly a finite amount of archaeological evidence buried below the surface, in some way our knowledge is never complete, because some (many) patches of land remain unexplored. This makes the evidence, sensu data, close to infinite in the sense that we will never be sure whether we are missing any pieces or not.\n\nKristiansen, K. 2014 Towards a New Paradigm? The Third Science Revolution and its Possible Consequences in Archaeology. Current Swedish Archaeology 22(1): 11–34. DOI: https://doi.org/10.37718/CSA.2014.01.\nWylie addresses these aspects of archaeological data as notorious incompleteness and fragmentarity. What more, she stresses that archaeological data is always burdened by the interpretive scaffoldings, that is, the theories and models individual archaeologists, the active agents in the data creation process, carry with themselves. This poses a conundrum. If we accept the theory-driven aspect of archaeology described in the previous section we approach data recording with certain models in mind, and in turn we fail to recognize and record evidence that does not conform to our expectation, to paraphrase Wylie. If we stick to the data-driven aspect of archaeology, we fail to recognize that the data we are re-using was created by someone with certain models and theories in mind. These examples are obviously great simplifications, but illustrate the point that no archaeological data exist without theory, models or expectations in their provenance.\nLastly, Hugget’s assertion adds unknown unknowns to the mix of archaeological data.\nTODO: Defining archaeological data, micro- to macro-scales;",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/theory.html#sec-quality",
    "href": "chapters/theory.html#sec-quality",
    "title": "1  Theory and method",
    "section": "1.5 Assessing data infrastructures",
    "text": "1.5 Assessing data infrastructures\nIn this section I define a framework for an assessment of the quality of data infrastructures. As there are some signs of good-quality data (as cited from Kitchin (2022: 4) in the Section 1.1.1), i.e. they are discreet and intelligible, aggregative, have associated metadata and can be linked to other datasets, by extension, good-quality data infrastructures allow data to be discreet and separable from other data, enable data aggregation, contain metadata and allow linking to other data sources. This gives us a general idea about requirements for a data infrastrucutre, but is difficult to assess in practice. These general ideas are concretized and further developed by the FAIR data principles (Wilkinson et al. 2016), which are aimed at enhancing the reusability of data holdings with an emphasis on the ability of machines to find and use the data. The FAIR data principles are measurable what gives us an opportunity to assess how FAIR an infrastructure is.\n\nFAIR data principles, i.e. findability, accessibility, interoperability and reusability, as originally defined by Wilkinson et al. (2016: 4), are as follows. To be findable, data and metadata have globally unique and persistent identifiers; are described with rich metadata which include the identifier of the data they describe; and are registered or indexed in a searchable resource. To be accessible, (meta)data are retrievable by the identifier using a standardized (open, free and universally implementable) communications protocol that allows for an authentication and authorization procedure; and metadata are accessible, even when the data are no longer available. To be interoperable, (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation; contain vocabularies that follow FAIR principles; and include qualified references to other (meta)data. To be reusable, meta(data) are richly described with a plurality of accurate and relevant attributes; are released with a clear and accessible data usage license; are associated with detailed provenance; and meet domain-relevant community standards.\n\nWith archaeology audiences in mind, the principles are further explained together with tips for implementations etc. by Hollander et al. (2019). Here I build up on Wilkinson et al. (2016) and Hollander et al. (2019) to come up with a set of formal, i.e. measurable and/or determinable criteria for assessment of data infrastructures. This framework is then used to evaluate archaeology data infrastructures in the Czech Republic in Chapter 2.\n\nHollander, H, Morselli, F, Uiterwaal, F, Admiraal, F, Trippel, T and Giorgio, SD. 2019 PARTHENOS Guidelines to FAIRify data management and make data reusable DOI: https://doi.org/10.5281/zenodo.2668478.\n\nWilkinson, MD, Dumontier, M, Aalbersberg, IjJ, Appleton, G, Axton, M, Baak, A, Blomberg, N, Boiten, J-W, da Silva Santos, LB, Bourne, PE, Bouwman, J, Brookes, AJ, Clark, T, Crosas, M, Dillo, I, Dumon, O, Edmunds, S, Evelo, CT, Finkers, R, Gonzalez-Beltran, A, Gray, AJG, Groth, P, Goble, C, Grethe, JS, Heringa, J, ’t Hoen, PAC, Hooft, R, Kuhn, T, Kok, R, Kok, J, Lusher, SJ, Martone, ME, Mons, A, Packer, AL, Persson, B, Rocca-Serra, P, Roos, M, van Schaik, R, Sansone, S-A, Schultes, E, Sengstag, T, Slater, T, Strawn, G, Swertz, MA, Thompson, M, van der Lei, J, van Mulligen, E, Velterop, J, Waagmeester, A, Wittenburg, P, Wolstencroft, K, Zhao, J and Mons, B. 2016 The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data 3(160018): DOI: https://doi.org/10.1038/sdata.2016.18.\n\n1.5.1 Assessment framework\nAssessment criteria are grouped together according to the FAIR principle they relate to. Table 1.1 lists criteria for findability of resources. Data should be easy to find by both humans and machines and well documented by metadata in order to be reusable by other researchers. To be able to use the data object in any way, it must be possible to uniquely identify it, find it, and refer to it (F1). This implies that an identifier of some sort, preferably persistent, i.e. immutable and long-lasting, is assigned to the resource (data and/or metadata). Persistent identifiers typically take form of DOIs, Handles, PURLs and URNs to name just a few examples4.\n4 Handles and DOIs (Digital Object Identifiers) are composed of a prefix/suffix and typically resolved at https://doi.org/. URNs (Uniform Resource Names), in form urn:namespace:name, are mostly used in the Semantic Web and are not resolvable, i.e. URNs do not have information about the location of the object. PURLs (Persistent Uniform Resource Locators) are an extension of URLs and are resolvable. URNs and (P)URLs are both subsets of URIs (Uniform Resource Identifiers). See e.g. DuCharme (2013: 21–23) for details.\nMarwick, B and Birch, SEP. 2018 A Standard for the Scholarly Citation of Archaeological Data as an Incentive to Data Sharing. Advances in Archaeological Practice 6(2): 125–143. DOI: https://doi.org/10.1017/aap.2018.3.\n\nDuCharme, B. 2013. Learning SPARQL: Querying and updating with SPARQL 1.1. Second edition. Sebastopol, CA: O’Reilly Media.\nFurthermore, it is convenient to be able to locate the resource (preferably on the internet) if the identifier, and possibly prefix of some sort, is known (F2). Since Marwick and Birch (2018) explore the lack of data citation and reuse in archaeology and suggest a standard for data citation, one of the criteria is whether the infrastructure makes it easy to cite the resources it publishes (F3). Another feature that enables findability of data is a rich metadata description (F4–F5).\n\n\n\n\nTable 1.1: Framework for quality assessment of data infrastrastructres, Findability\n\n\n\n\n\n\n\n\n\n\n\nID\nFindability\nValue\n\n\n\n\nF1.1\nAre there unique identifiers?\nTrue/False\n\n\nF1.2\nAre the identifiers persistent?\nTrue/False\n\n\nF1.3\nAre the identifiers in any standard form?\nTrue/False\n\n\nF2\nIs it possible to locate the resource by the identifier?\nTrue/False\n\n\nF3\nIs it possible (and made easy) to cite:\n-\n\n\nF3.1\n- the data infrastructure,\nTrue/False\n\n\nF3.2\n- its parts and/or\nTrue/False\n\n\nF3.3\n- individual resources?\nTrue/False\n\n\nF4.1\nIs the metadata scheme described, i.e. explicit?\nTrue/False\n\n\nF4.2\nDoes the metadata scheme follow a standard?\nTrue/False\n\n\nF5\nAre the metadata searchable?\nTrue/False\n\n\n\n\n\n\n\n\nCriteria for accessibility are listed in Table 1.2. Accessible data are retrievable under well-defined conditions using standardised protocols. Certification of a data infrastructure guarantees that its repository is trustworthy, the data are stored safely and will be available over a long period of time. Certifications may include CoreTrustSeal, nestor seal etc. (A1). By a standardised exchange protocol (A2.1) a well-documented technology created and maintained by a recognized authority (e.g. World Wide Web Consortium, W3C) is meant. For example SPARQL is a query language for semantic data created by W3C, OAI-PMH, a Protocol for Metadata Harvesting, is created and maintained by the Open Archives Initiative etc. By a standardised format (A2.2) a machine-readable format is meant, for instance XML, a W3C format for hierarchical data representation, RDF, a W3C standard for semantic data, etc.\nFor (meta)data to be easily accessible, the policies for the access need to be clearly stated (A3), i.e. definitions of who can access what and when needs to be explicitly communicated, for example existence of differentiated user roles and/or embargo periods. This gives both the users accessing the data clear instructions on how to access the objects they need, and the users depositing the data sets options to protect sensitive data etc. Existence of policies how to handle situations if a data object is no longer available (e.g. deleted, superseded etc.) and presence of metadata tombstones is a good practice how to communicate that a data object existed, but does not anymore (A4).\n\n\n\n\nTable 1.2: Framework for quality assessment of data infrastrastructres, Accessibility\n\n\n\n\n\n\n\n\n\n\n\nID\nAccessibility\nValue\n\n\n\n\nA1\nIs the repository trustworthy?\nTrue/False\n\n\nA2.1\nAre the (meta)data retrievable using a standardised protocol?\nTrue/False\n\n\nA2.2\nAre the metadata in a standardised format?\nTrue/False\n\n\nA3\nIs the access policy clearly stated?\nTrue/False\n\n\nA3.1\nAre there embargo periods?\nTrue/False\n\n\nA3.2\nAre the access rights differentiated?\nTrue/False\n\n\nA4\nIs the metadata available even after the data is not?\nTrue/False\n\n\n\n\n\n\n\n\nInteroperability is the ability of the (meta)data to be easily combined with other data sets, Table 1.3 lists the interoperability criteria relevant to data infrastructures. Machine interoperability is closely related to the availability of APIs and their quality and human interoperability derives from the existence and extensiveness of documentation.\nTo enable interoperability, (meta)data model5 needs to be described clearly and accessibly (I1) and employed controlled vocabularies need to be explained and published, preferably following the FAIR principles (I2). Explanation of the given data model and vocabularies describing exact meanings embedded in the data are a prerequisites for building understanding by other people. Furthermore, well-documented (meta)data models allow creation of mappings between different metadata schemes and data infrastructures. Similarly, the existence of machine actionable APIs (application programming interfaces, I4) that allow harvesting of (meta)data through standardised protocols and return responses in standardised formats (cf. A2) ensure machine interoperability.\n5 The term data model is used here in the sense of how phenomena present, observed and/or measured in the real world are encoded in the data, what ratinale is behind the chosen abstraction process, and what is actually meant by the given wording.\n\n\n\nTable 1.3: Framework for quality assessment of data infrastrastructres, Interoperability\n\n\n\n\n\n\nID\nInteroperability\nValue\n\n\n\n\nI1\nIs the (meta)data model explained and documented?\nTrue/False\n\n\nI2.1\nAre the vocabularies published and/or well-known?\nTrue/False\n\n\nI2.2\nAre the vocabularies FAIR?\nTrue/False\n\n\nI3\nAre other metadata referenced properly?\nTrue/False\n\n\nI4.1\nIs there a machine-actionable API?\nTrue/False\n\n\nI4.2\nIs the API well documented?\nTrue/False\n\n\n\n\n\n\n\n\nBy reusability the process of making data ready for future processing and analysis is meant. This is crucial for reproducibility of scientific research. Data, repositories and infrastructures that are systematically documented by manuals, tutorials, guides, codebooks etc. and transparent about what they do and do not contain foster reuse, because researchers reusing the data have clear notion of what to expect from the data source (R1). Reusability is also enhanced by using widely used and open source file formats (R2). In the long run, long-term preservation (LTP) is a prerequisite for reusability, because if the file format in which the data is saved gets obsolete, it is often difficult to retrieve the original data, see Brin et al. (2013) for recommended file formats, online as Guides to Good Practice (n.d.).\n\nBrin, A, McManamon, FP, Niven, K, Archaeology Data Service and Digital Antiquity (eds.). 2013. Caring for digital data in archaeology: A guide to good practice. Archaeology Data Service and Digital Antiquity. Oxford ; Oakville: Oxbow Books.\n\nArchaeology Data Service and Digital Antiquity. n.d. Guides to Good Practice. Available at https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/ [Last accessed August 18, 2023].\nIntegrity of the (meta)data and existence of multiple versions of the given data objects is also important to consider, because if this information is not properly communicated, different versions of the data objects with identical identifiers might get mixed up (R3). This closely relates to the provenance of the data, i.e. the documentation of the origin of the data object and record of any changes with a rationale behind these processes. Knowing why changes in the (meta)data happened, whether it was a correction of a previous mistake or something else, might be useful for data reuse in the future. Lastly, releasing the (meta)data with proper license information, preferably under a standard data license, for instance a Creative Commons Licence, and any information on a rights holder is neccessary for future reuse because without this information, it is unclear what the terms of (meta)data use are.\n\n\n\n\nTable 1.4: Framework for quality assessment of data infrastrastructres, Reusability\n\n\n\n\n\n\n\n\n\n\n\nID\nReusability\nValue\n\n\n\n\nR1\nAre there documentation, manuals, tutorials etc?\nTrue/False\n\n\nR2.1\nAre common file formats used?\nTrue/False\n\n\nR2.2\nAre file formats suitable for long-term preservation?\nTrue/False\n\n\nR3.1\nIs the (meta)data provenance documented?\nTrue/False\n\n\nR3.2\nAre there any version control mechanisms in place?\nTrue/False\n\n\nR4.1\nAre the rights holders and terms of use clear?\nTrue/False\n\n\nR4.2\nAre the resources released under a standard license?\nTrue/False\n\n\n\n\n\n\n\n\nThe framework consists predominantly of qualities that are measurable and builds up on the FAIR data principles. CARE data principles, as defined by Carroll et al. (2020), were considered as well, but their goal is to increase the indigenous data sovereignity and self-determination by being people and purpose-oriented, while the FAIR data principles are primarily focused on the characteristics of the data. CARE data principles are put together to address imbalances of power in the knowledge societies and economies and protect indigenous and human rights. Hence the extent to which a data infrastructure adheres to CARE data principles is difficult to determine and/or measure.\n\nCarroll, SR, Garba, I, Figueroa-Rodríguez, OL, Holbrook, J, Lovett, R, Materechera, S, Parsons, M, Raseroka, K, Rodriguez-Lonebear, D, Rowe, R, Sara, R, Walker, JD, Anderson, J and Hudson, M. 2020 The CARE Principles for Indigenous Data Governance. Data Science Journal 19: 43. DOI: https://doi.org/10.5334/dsj-2020-043.\nThe framework for assessment of the quality of data infrastructures is used in Chapter 2 to evaluate the quality of archaeology data infrastructures in the Czech Republic.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/theory.html#sec-software",
    "href": "chapters/theory.html#sec-software",
    "title": "1  Theory and method",
    "section": "1.6 Software",
    "text": "1.6 Software\nMost of the things included here, if not all of them, were achieved using open-source software. Large part of this endeavor is also documented in code. This text was written in plain text with some basic markdown and quarto syntax for formatting, cross references, citations etc. At some places there are R code blocks. The text is processed into three outputs, a website (HTML document), a PDF document and a MS Word document using Quarto. The plain text version, same as the rendered website, is hosted at GitHub. The text was mostly written in the Visual Code Studio, analysis were mostly performed using Rstudio or terminal. Library was organized using Zotero.\nRaster graphics were created and edited using GIMP, vector graphics using Inkscape. All the GIS operations that required graphical user interface (GUI), or were more conveniently performed in a GUI, were done in QGIS.\nSome data were prepared, extracted or processed using basic GNU/Linux shell or SQL commands or scripts. Data from Wikidata was queried using SPARQL. Any analysis was mostly done in R, a language for statistical computing and graphics (R Core Team 2023). Various packages were used, the most important packages are listed here, the complete list is in an Appendix\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing.\n\n1.6.1 Reproduciblity",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/theory.html#chapter-summary",
    "href": "chapters/theory.html#chapter-summary",
    "title": "1  Theory and method",
    "section": "Chapter summary",
    "text": "Chapter summary",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Theory and method</span>"
    ]
  },
  {
    "objectID": "chapters/data.html",
    "href": "chapters/data.html",
    "title": "2  Data and materials",
    "section": "",
    "text": "2.1 Sources of archaeology data in the Czech Republic",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data and materials</span>"
    ]
  },
  {
    "objectID": "chapters/data.html#sec-sources",
    "href": "chapters/data.html#sec-sources",
    "title": "2  Data and materials",
    "section": "",
    "text": "2.1.1 Archaeological information system of the Czech Republic\n\n\n\n\n\n\nConflict of interest disclosure\n\n\n\nSince 2018 I am part of the AIS CR team at the Institute of Archaeology, Czech Academy of Sciences, Brno and since 2023 I am a member of the executive committee of this project. This text is thus influenced by my inside view of how the infrastructure works.\n\n\n\n\n2.1.2 Information system about archaeological data\n\n\n2.1.3 Legacy data sources\nWhat is a legacy data source?\n\n\n2.1.4 Museum databases\n\n\n2.1.5 Other pre-existing data\nThere are several well published data sets covering the area of the Czech Republic in the Journal of Open Archaeology Data, the radiocarbon data by Tkáč and Kolář (2021) and the Neolithic settlements data set by Pajdla and Trampota (2021). These have an advantage of well formulated access and re-use policies, explicit licence and other conditions for use.\n\nTkáč, P and Kolář, J. 2021 Towards New Demography Proxies and Regional Chronologies: Radiocarbon Dates from Archaeological Contexts Located in the Czech Republic Covering the Period Between 10,000 BC and AD 1250. Journal of Open Archaeology Data 9(0, 0): 9. DOI: https://doi.org/10.5334/joad.85.\n\nPajdla, P and Trampota, F. 2021 Neolithic Settlements in Central Europe: Data from the Project “Lifestyle as an Unintentional Identity in the Neolithic.” Journal of Open Archaeology Data 9(0, 0): 13. DOI: https://doi.org/10.5334/joad.88.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data and materials</span>"
    ]
  },
  {
    "objectID": "chapters/data.html#sec-dmp",
    "href": "chapters/data.html#sec-dmp",
    "title": "2  Data and materials",
    "section": "2.2 Data management",
    "text": "2.2 Data management\n\n\n\n\n\n\nNote\n\n\n\nThis section builds up on the project Data management in Archaeology I cooperated on with Hana Kubelková in 2021 at the Department of Archaeology and Museology, Faculty of Arts, Masaryk University.\n\n\nGood data stewardship is a crucial element in Open Science (Mons 2018: 1–5), an umbrella concept for how scientific research is conducted in a way that knowledge is reusable, modifiable and redistributable. The data management plan (DMP) then stands at the very beginning of every such endeavour. In its essence, a DMP is a stand-alone document detailing how data is handled at each of the steps in its life cycle. This implies that it is not a static, but a living record of how the data was captured, created, curated, selected, analysed, interpreted, shared, and archived in the course of a project or after its end. A DMP helps in adhering to the FAIR principles, i.e. making data findable, accessible, interoperable and reusable, a set of propositions enabling more effective knowledge discovery, collaboration, and data reuse (Hollander et al. 2019; Wilkinson et al. 2016).\n\nMons, B. 2018. Data Stewardship For Open Science: Implementing FAIR principles. Boca Raton: CRC Press, Taylor & Francis Group.\n\nHollander, H, Morselli, F, Uiterwaal, F, Admiraal, F, Trippel, T and Giorgio, SD. 2019 PARTHENOS Guidelines to FAIRify data management and make data reusable DOI: https://doi.org/10.5281/zenodo.2668478.\n\nWilkinson, MD, Dumontier, M, Aalbersberg, IjJ, Appleton, G, Axton, M, Baak, A, Blomberg, N, Boiten, J-W, da Silva Santos, LB, Bourne, PE, Bouwman, J, Brookes, AJ, Clark, T, Crosas, M, Dillo, I, Dumon, O, Edmunds, S, Evelo, CT, Finkers, R, Gonzalez-Beltran, A, Gray, AJG, Groth, P, Goble, C, Grethe, JS, Heringa, J, ’t Hoen, PAC, Hooft, R, Kuhn, T, Kok, R, Kok, J, Lusher, SJ, Martone, ME, Mons, A, Packer, AL, Persson, B, Rocca-Serra, P, Roos, M, van Schaik, R, Sansone, S-A, Schultes, E, Sengstag, T, Slater, T, Strawn, G, Swertz, MA, Thompson, M, van der Lei, J, van Mulligen, E, Velterop, J, Waagmeester, A, Wittenburg, P, Wolstencroft, K, Zhao, J and Mons, B. 2016 The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data 3(160018): DOI: https://doi.org/10.1038/sdata.2016.18.\n\nPergl, R, Hooft, R, Suchánek, M, Knaisl, V and Slifka, J. 2019 “Data Stewardship Wizard”: A Tool Bringing Together Researchers, Data Stewards, and Data Experts around Data Management Planning. Data Science Journal 18(1, 1): 59. DOI: https://doi.org/10.5334/dsj-2019-059.\n\nDoorn, P and Ronzino, P. 2022. ARIADNEplus Data Management Plan Tools. 25 March 2022. Available at https://vast-lab.org/dmp/ [Last accessed November 17, 2022].\nThe DMP included as Appendix B is generated by Data Stewardship Wizard (DSW, Pergl et al. 2019), an online tool dedicated to cooperative creation of data management plans. It is included both as part of the text and as a standalone machine actionable file. The notes below take into account templates for data management planning created in the Ariadne project (Doorn and Ronzino 2022) as well as the DSW template.\n\n2.2.1 Data re-use\nThe work is predominantly based on re-using existing data. The sources of data are listed and described in detail in the beginning of this chapter (ie. Section 2.1).\nThe single most complete source for archaeology data in the Czech Republic is without a doubt the AIS CR infrastructure. The (meta)data of AIS CR infrastrucutre are accessed through a public OAI-PMH API. This data is published under the CC BY-NC 4.0 International license, what makes the conditions for its use clear and transparent.\nAIS CR data is aggregated in the ARIADNE infrastructure is accessed through SPARQL endpoint of the dedicated triple store.\nThe spatial data from ISAD is queried from an ArcGIS rest API. The attributes for this data, ie. SAS database, is webscraped, because it is not published in any other machine-readable form. The ISAD is licensed under CC BY-SA 4.0 International license and SAS metadata, as an integral part of the ISAD ecosystem falls under this license as well, although this fact is not explicitly stated on the website.\nThe data is accessed through custom scripts developed in the R language.\nI presume that there are many pre-existing data sets in the Czech archaeology, but most of them are either inaccessible or not findable, i.e. we cannot be sure they even exist.\n\n\nData creation and collection\nNo new data is collected or created per se, but re-used data sources are processed, remixed, interlinked etc. into new, different, data. Vector spatial data is stored as geodatabases in OGC GeoPackage, most of other data is stored as comma separated values (CSV) files. Both formats are open standards, CSV is well suited for logn term preservation (LTP) of text-based data. Preservation of code and data is planned in a sense that whole repository of this project will be deposited at Zenodo trustworthy repository and independently archived by the university.\n\n\n\nControlled vocabularies and ontologies\n\nI am explicitly using vocabularies that are inherent to data sources from which the data is reused. A principal and authoritative vocabulary for archaeology and related fields is the Getty Art & Architecture Thesaurus (AAT). Getty AAT subjects are used by the ARIADNE infrastructure and many other archaeology infrastructures are mapping their vocabularies to the AAT subjects. The emerging ARIADNE AO_Cat formal ontology is also taken into account when interacting with ARIADNE services. The AIS CR vocabularies, although implicit to the data, are yet to be published. A possibly incomplete version can be reverse engineered from the available data sets. If reconciliation between data from different data sources is necessary, the AAT is used to map between them.\n\n\n\n2.2.2 Data processing\n\nData is processed predominantly in the R programming language and environment using varius packages and custom written scripts (see Section 1.6 for detailed overview of software used and how reproducibility is handled). Changes in data, code and text are recorded using a version control system git and preserved online in a repository at GitHub.\n\n\n\n2.2.3 Data preservation\nWhat data sets are you producing? Is data long-term archived? Will it be usable and accessible after a long period of time?\n\n\n2.2.4 Access to data and code\nThe data used in this work will be as open as possible, as most of the data is licensed under one of the CC BY-NC or CC BY-SA licenses. The code developed here is published under a very permissive and simple MIT license, where appropriate. As already mentioned, the whole repository will be deposited at Zenodo data repository, as well as archived by the university and already is availbale throuh GitHub interface, including the record of the changes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data and materials</span>"
    ]
  },
  {
    "objectID": "chapters/data.html#chapter-summary",
    "href": "chapters/data.html#chapter-summary",
    "title": "2  Data and materials",
    "section": "Chapter summary",
    "text": "Chapter summary",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data and materials</span>"
    ]
  },
  {
    "objectID": "biblio/references.html",
    "href": "biblio/references.html",
    "title": "References",
    "section": "",
    "text": "Anderson, C. 2008 The\nEnd of Theory: The Data Deluge\nMakes the Scientific Method Obsolete.\nWired.\n\n\nAnon. 2002 Act No 130/2002 Coll. (The\nAct on the Support of Research,\nExperimental Development and Innovation), as\namended.\n\n\nAnon. 2019. Roadmap\nof Large Research Infrastructures of the Czech\nRepublic for the years 2016-2022. Update 2019.\nPrague: Ministry of Education, Youth and\nSports.\n\n\nAnon. 2021 Regulation\n(EU) 2021/695 of the European Parliament and\nof the Council. 32021R0695.\n\n\nArchaeology Data Service and Digital Antiquity. n.d. Guides to\nGood Practice. Available at https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/\n[Last accessed 18 August 2023].\n\n\nBevan, A. 2015 The data deluge. Antiquity 89(348): 1473–1484.\nDOI: https://doi.org/10.15184/aqy.2015.102.\n\n\nBox, GEP. 1976 Science and Statistics. Journal of the\nAmerican Statistical Association 71(356): 791–799. DOI:\nhttps://doi.org/10.1080/01621459.1976.10480949.\n\n\nBox, GEP. 1979 Robustness in the Strategy of\nScientific Model Building. In: Launer, RL and Wilkinson, GN\n(eds.). Robustness in Statistics. Academic\nPress. pp. 201–236. DOI: https://doi.org/10.1016/B978-0-12-438150-6.50018-2.\n\n\nBrin, A, McManamon, FP, Niven, K, Archaeology Data Service and Digital\nAntiquity (eds.). 2013. Caring for digital data in archaeology:\nA guide to good practice. Archaeology Data\nService and Digital Antiquity. Oxford ;\nOakville: Oxbow Books.\n\n\nCarroll, SR, Garba, I, Figueroa-Rodríguez, OL, Holbrook, J, Lovett, R,\nMaterechera, S, Parsons, M, Raseroka, K, Rodriguez-Lonebear, D, Rowe, R,\nSara, R, Walker, JD, Anderson, J and Hudson, M. 2020 The CARE\nPrinciples for Indigenous Data Governance. Data\nScience Journal 19: 43. DOI: https://doi.org/10.5334/dsj-2020-043.\n\n\nDoorn, P and Ronzino, P. 2022. ARIADNEplus Data Management\nPlan Tools. 25 March 2022. Available at https://vast-lab.org/dmp/ [Last\naccessed 17 November 2022].\n\n\nDuCharme, B. 2013. Learning SPARQL: Querying and\nupdating with SPARQL 1.1. Second edition.\nSebastopol, CA: O’Reilly Media.\n\n\nHallonsten, O. 2020 Research Infrastructures in\nEurope: The Hype and the Field.\nEuropean Review 28(4): 617–635. DOI: https://doi.org/10.1017/S1062798720000095.\n\n\nHollander, H, Morselli, F, Uiterwaal, F, Admiraal, F, Trippel, T and\nGiorgio, SD. 2019 PARTHENOS Guidelines to\nFAIRify data management and make data reusable DOI:\nhttps://doi.org/10.5281/zenodo.2668478.\n\n\nHuggett, J. 2020 Is Big Digital Data Different?\nTowards a New Archaeological Paradigm.\nJournal of Field Archaeology 45: S8–S17. DOI:\nhttps://doi.org/10.1080/00934690.2020.1713281.\n\n\nKitchin, R. 2022. The data revolution: A critical\nanalysis of big data, open data & data infrastructures. 2nd ed.\nLos Angeles, California: SAGE Publications.\n\n\nKristiansen, K. 2014 Towards a New Paradigm? The\nThird Science Revolution and its Possible\nConsequences in Archaeology. Current Swedish\nArchaeology 22(1): 11–34. DOI: https://doi.org/10.37718/CSA.2014.01.\n\n\nMaass, W, Parsons, J, Purao, S, Storey, VC and Woo, C. 2018\nData-Driven Meets Theory-Driven Research in the\nEra of Big Data: Opportunities\nand Challenges for Information Systems\nResearch. Journal of the Association for Information\nSystems 1253–1273. DOI: https://doi.org/10.17705/1jais.00526.\n\n\nMarwick, B. 2017 Computational Reproducibility in\nArchaeological Research: Basic Principles and\na Case Study of Their Implementation.\nJournal of Archaeological Method and Theory 24(2): 424–450.\nDOI: https://doi.org/10.1007/s10816-015-9272-9.\n\n\nMarwick, B and Birch, SEP. 2018 A Standard for the\nScholarly Citation of Archaeological Data as\nan Incentive to Data Sharing. Advances in\nArchaeological Practice 6(2): 125–143. DOI: https://doi.org/10.1017/aap.2018.3.\n\n\nMarwick, B, Boettiger, C and Mullen, L. 2018 Packaging Data\nAnalytical Work Reproducibly Using R (and Friends).\nThe American Statistician 72(1): 80–88. DOI: https://doi.org/10.1080/00031305.2017.1375986.\n\n\nMons, B. 2018. Data Stewardship For Open Science:\nImplementing FAIR principles. Boca Raton:\nCRC Press, Taylor & Francis Group.\n\n\nPajdla, P and Trampota, F. 2021 Neolithic Settlements in\nCentral Europe: Data from the\nProject ‘Lifestyle as an\nUnintentional Identity in the\nNeolithic’. Journal of Open Archaeology\nData 9(0, 0): 13. DOI: https://doi.org/10.5334/joad.88.\n\n\nPergl, R, Hooft, R, Suchánek, M, Knaisl, V and Slifka, J. 2019\n‘Data Stewardship Wizard’: A Tool\nBringing Together Researchers, Data Stewards, and\nData Experts around Data Management Planning.\nData Science Journal 18(1, 1): 59. DOI: https://doi.org/10.5334/dsj-2019-059.\n\n\nR Core Team. 2023. R: A\nLanguage and Environment for Statistical\nComputing. Vienna, Austria: R\nFoundation for Statistical Computing.\n\n\nRosenberg, D. 2013 Data before the fact. In: Gitelman, L (ed.).\n’Raw Data’ is an Oxymoron.\nCambridge, MA: MIT Press. pp. 15–40.\n\n\nRuppert, E, Isin, E and Bigo, D. 2017 Data politics. Big Data &\nSociety 4(2): 2053951717717749. DOI: https://doi.org/10.1177/2053951717717749.\n\n\nTkáč, P and Kolář, J. 2021 Towards New Demography Proxies\nand Regional Chronologies: Radiocarbon Dates\nfrom Archaeological Contexts Located in the Czech\nRepublic Covering the Period Between 10,000\nBC and AD 1250. Journal of Open\nArchaeology Data 9(0, 0): 9. DOI: https://doi.org/10.5334/joad.85.\n\n\nUNESCO. 2021 UNESCO\nRecommendation on Open Science.\n\n\nWilkinson, MD, Dumontier, M, Aalbersberg, IjJ, Appleton, G, Axton, M,\nBaak, A, Blomberg, N, Boiten, J-W, da Silva Santos, LB, Bourne, PE,\nBouwman, J, Brookes, AJ, Clark, T, Crosas, M, Dillo, I, Dumon, O,\nEdmunds, S, Evelo, CT, Finkers, R, Gonzalez-Beltran, A, Gray, AJG,\nGroth, P, Goble, C, Grethe, JS, Heringa, J, ’t Hoen, PAC, Hooft, R,\nKuhn, T, Kok, R, Kok, J, Lusher, SJ, Martone, ME, Mons, A, Packer, AL,\nPersson, B, Rocca-Serra, P, Roos, M, van Schaik, R, Sansone, S-A,\nSchultes, E, Sengstag, T, Slater, T, Strawn, G, Swertz, MA, Thompson, M,\nvan der Lei, J, van Mulligen, E, Velterop, J, Waagmeester, A,\nWittenburg, P, Wolstencroft, K, Zhao, J and Mons, B. 2016 The FAIR\nGuiding Principles for scientific data management and\nstewardship. Scientific Data 3(160018): DOI: https://doi.org/10.1038/sdata.2016.18.\n\n\nWylie, A. 2017 How Archaeological Evidence Bites Back:\nStrategies for Putting Old Data to\nWork in New Ways. Science, Technology,\n& Human Values 42(2): 203–225. DOI: https://doi.org/10.1177/0162243916671200.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "appendices/glossary.html",
    "href": "appendices/glossary.html",
    "title": "Appendix A — Glossary and abbreviations",
    "section": "",
    "text": "A.1 Institutions, infrastructures, services etc.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Glossary and abbreviations</span>"
    ]
  },
  {
    "objectID": "appendices/glossary.html#institutions-infrastructures-services-etc.",
    "href": "appendices/glossary.html#institutions-infrastructures-services-etc.",
    "title": "Appendix A — Glossary and abbreviations",
    "section": "",
    "text": "AAT, Getty AAT\n\nGetty Art & Architecture Thesaurus\n\nAIS CR\n\nArchaeological information system of the Czech republic (Archeologický informační systém České republiky, https://aiscr.cz/). Central data infrastructure in the Czech republic operated jointly by Institutes of Archaeology of the Czech Academy of Sciences in Prague and Brno. Its main component is the AMČR.\n\nAMČR\n\nArchaeological map of the Czech republic (Archeologická mapa České republiky, https://amcr-info.aiscr.cz/). A backbone ecosystem of AIS CR gathering data on archaeological fieldworks in the Czech republic.\n\nARIADNE\n\nARIADNE (https://ariadne-infrastructure.eu/) is an international infrastructure devoted to archaeological data preservation and sharing. ARIADNE is operating ARIADNE Portal, a central point of access to archaeological resources offered by different partner institutions.\n\nARUB\n\nInstitute of Archaeology, Czech Academy of Sciences, Brno (https://www.arub.cz/).\n\nARUP\n\nInstitute of Archaeology, Czech Academy of Sciences, Prague (https://www.arup.cas.cz)\n\nISAD\n\nInformation system about archaeological data (Informační systém o archeologických datech, https://isad.npu.cz/), an information system operated by the NHI. ISAD consists in principle of spatial data and its metadata, ie. SAS.\n\nNHI (NPÚ)\n\nNational Heritage Institute (Národní památkový ústav, https://npu.cz/).\n\nNM\n\nNatinal Museum (Národní muzeum, https://www.nm.cz/)\n\nSAS\n\nState archaeological list (Státní archeologický seznam), part of ISAD operated by the NHI.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Glossary and abbreviations</span>"
    ]
  },
  {
    "objectID": "appendices/glossary.html#other-abbreviations",
    "href": "appendices/glossary.html#other-abbreviations",
    "title": "Appendix A — Glossary and abbreviations",
    "section": "A.2 Other abbreviations",
    "text": "A.2 Other abbreviations\n\nDMP\n\nData management plan, also data stewardship plan.\n\nDSW\n\nData stewardship wizard (https://ds-wizard.org/), an online tool for DMP creation. A FAIR Wizard, an instance of DSW operated by the Czech Academy of Sciences, was used to create a DMP enclosed as Appendix B.\n\nFAIR data\n\nFindable, interoperable, accessible and reusable data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Glossary and abbreviations</span>"
    ]
  },
  {
    "objectID": "appendices/dmp.html#section-a-data-collection",
    "href": "appendices/dmp.html#section-a-data-collection",
    "title": "Appendix B — Data management plan",
    "section": "B.1 Section A: Data Collection",
    "text": "B.1 Section A: Data Collection\n\n\nB.1.1 1. What data will you collect or create?\n\n\nRe-used datasets\nWe have found the following non-reference datasets that we have considered for re-use:\n\nArchaeological Map of the Czech Republic (AMCR) \nThe Archaeological Map of the Czech Republic (AMCR) is a repository designed for information on archaeological investigations, sites and finds, operated by the Archaeological Institutes of the CAS in Prague and Brno. The archives of these institutions contain documentation of archaeological fieldwork on the territory of the Czech Republic from 1919 to the present day, and they continue to enrich their collections. The AMCR database and related documents form the largest collection of archaeological data concerning the Czech Republic and are therefore an important part of our cultural heritage. The AMCR digital archive contains various types of records - individual archaeological documents (texts, field photographs, aerial photographs, maps and plans, digital data), projects, fieldwork events, archaeological sites, records of individual finds and a library of 3D models. Data and descriptive information are continuously taken from the AMCR and presented in the the AMCR Digital Archive interface.\n\n\n\nData formats and types\nWe will be using the following data formats and types:\n\nComma-separated Values (CSV) \nA comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. The use of the comma as a field separator is the source of the name for this file format. A CSV file typically stores tabular data (numbers and text) in plain text, in which case each line will have the same number of fields.\nIt is a standardized format. This is a suitable format for long-term archiving. We will have only a small amount of data stored in this format.\nOGC Geoackage\nIt is a standardized format. This is a suitable format for long-term archiving. We will have only a small amount of data stored in this format.\n\n\n\n\n\n\n\nB.1.2 2. How will the data be collected or created?\n\nThere will be no instrument dataset in this project.\n\nData storage and file conventions\nThe project will require so little storage space for all data and software (including temporary storage) that it is not a problem.\nWe will use a filesystem with files and folders. We document how we manage file versioning for files and folders.\nWe will not be storing data in an \"object/document store\" system.\nWe will not use a database system to store project data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  },
  {
    "objectID": "appendices/dmp.html#section-b-documentation-and-meta-data",
    "href": "appendices/dmp.html#section-b-documentation-and-meta-data",
    "title": "Appendix B — Data management plan",
    "section": "B.2 Section B: Documentation and Meta-data",
    "text": "B.2 Section B: Documentation and Meta-data\n\n\nB.2.1 3. What documentation and meta-data will accompany the data?\n\nList of data to be published is given in Section E, Question 9. This also includes information about catalogs where the data can be found. Information about data types used is given in Section A, Question 1.\nWe will include keywords and relevant ontology references to optimise the possibility for discovery and potential reuse.\nMetadata will be openly available. Metadata will available in a form that can be harvested and indexed (managed by the used repository / repositories).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  },
  {
    "objectID": "appendices/dmp.html#section-c-ethics-and-legal-compliance",
    "href": "appendices/dmp.html#section-c-ethics-and-legal-compliance",
    "title": "Appendix B — Data management plan",
    "section": "B.3 Section C: Ethics and Legal Compliance",
    "text": "B.3 Section C: Ethics and Legal Compliance\n\n\nB.3.1 4. How will you manage any ethical issues?\n\nData we collect\nWe will not collect any data connected to a person, i.e. \"personal data\".\nThe data collection is not subject to ethical legislation.\n\n\n\n\n\nB.3.2 5. How will you manage copyright and Intellectual Property Rights (IPR) issues?\n\nWe will be working with the philosophy as open as possible for our data.\nAll of our data can become completely open over time.\nLimited embargo will not be used as all data will be opened.\nAll data will be owned by the Principal Investigator.\nFor the reference and non-reference data sets that we reuse, conditions are as follows:\n\nArchaeological Map of the Czech Republic (AMCR) \nThe Archaeological Map of the Czech Republic (AMCR) is a repository designed for information on archaeological investigations, sites and finds, operated by the Archaeological Institutes of the CAS in Prague and Brno. The archives of these institutions contain documentation of archaeological fieldwork on the territory of the Czech Republic from 1919 to the present day, and they continue to enrich their collections. The AMCR database and related documents form the largest collection of archaeological data concerning the Czech Republic and are therefore an important part of our cultural heritage. The AMCR digital archive contains various types of records - individual archaeological documents (texts, field photographs, aerial photographs, maps and plans, digital data), projects, fieldwork events, archaeological sites, records of individual finds and a library of 3D models. Data and descriptive information are continuously taken from the AMCR and presented in the the AMCR Digital Archive interface.\nIt is freely available with obligation to quote the source (e.g. CC-BY).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  },
  {
    "objectID": "appendices/dmp.html#section-d-storage-and-backup",
    "href": "appendices/dmp.html#section-d-storage-and-backup",
    "title": "Appendix B — Data management plan",
    "section": "B.4 Section D: Storage and Backup",
    "text": "B.4 Section D: Storage and Backup\n\n\nB.4.1 6. How will the data be stored and backed up during the research?\n\nData that project members themselves store adequately backed up and traceable. Therefore data are protected against both equipment failure and human error.\n\n\n\n\n\nB.4.2 7. How will you manage access and security?\n\nProject members will not store data or software on computers in the lab or external hard drives connected to those computers.They can carry data with them on password-protected laptops. All data centers where project data is stored carry sufficient certifications. All project web services are addressed via secure HTTP (https://...). Project members have been instructed about both generic and specific risks to the project.\nThe possible impact to the project or organization if information is lost is small. The possible impact to the project or organization if information is leaked is small. The possible impact to the project or organization if information is vandalised is small.\nWe are not using any personal information.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  },
  {
    "objectID": "appendices/dmp.html#section-e-selection-and-preservation",
    "href": "appendices/dmp.html#section-e-selection-and-preservation",
    "title": "Appendix B — Data management plan",
    "section": "B.5 Section E: Selection and Preservation",
    "text": "B.5 Section E: Selection and Preservation\n\n\nB.5.1 8. Which data are of long-term value and should be retained, shared, and/or preserved?\n\n\n\n\n\n\n\nB.5.2 9. What is the longterm preservation plan for the dataset?\n\nNone of the used repositories charge for their services.\nWe have a reserved budget for the time and effort it will take to prepare the data for publication.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  },
  {
    "objectID": "appendices/dmp.html#section-f-data-sharing",
    "href": "appendices/dmp.html#section-f-data-sharing",
    "title": "Appendix B — Data management plan",
    "section": "B.6 Section F: Data Sharing",
    "text": "B.6 Section F: Data Sharing\n\n\nB.6.1 10. How will you share the data?\n\nInformation about used repositories (i.e. where will potential users find out about the data) is provided in Section E, Question 9.\nEmbargo on the data is described in Section C, Question 5, and Section F, Question 11.\n\n\n\n\n\nB.6.2 11. Are any restrictions on data sharing required?\n\nEthical and legal restrictions are documented under Section C. We have used the Data Stewardship Wizard, which made us aware of options to minimize the restrictions.\nNo data sharing agreement will be required.\nWe are not running the project in a collaboration between different groups nor institutes. Therefore, no collaboration agreement related to data access is needed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  },
  {
    "objectID": "appendices/dmp.html#section-g-responsibilities-and-resources",
    "href": "appendices/dmp.html#section-g-responsibilities-and-resources",
    "title": "Appendix B — Data management plan",
    "section": "B.7 Section G: Responsibilities and Resources",
    "text": "B.7 Section G: Responsibilities and Resources\n\n\nB.7.1 12. Who will be responsible for data management?\n\nPetr Pajdla is responsible for implementing the DMP, and ensuring it is reviewed and revised.\nPetr Pajdla is responsible for reviewing, enhancing, cleaning, or standardizing metadata and the associated data submitted for storage, use and maintenance within a data centre or repository.\nPetr Pajdla is responsible for maintaining the finished resource.\n\n\n\n\n\nB.7.2 13. What resources will you require to deliver your plan?\n\nTo execute the DMP, no additional specialist expertise is required.\nWe do not require any hardware or software in addition to what is usually available in the institute.\nCharges applied by data repositories (if any) are mentioned already in Section E, Question 9.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  }
]