[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Archaeology Data Infrastructures",
    "section": "",
    "text": "Preface\n\n\n\n\n\n\nWarning\n\n\n\nThis is a website for the work-in-progress PhD thesis of mine. It is not intended to be read by anyone except me (and maybe few other people) yet. If you do flick through it anyway, consider yourself warned. It might be messy at some places and will definitely undergo serious rewriting.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis work can be read online at https://petrpajdla.github.io/dataInfrastructures/. The source repository is on GitHub at https://github.com/petrpajdla/dataInfrastructures/.\n\n\n\nThis document is created in an open-source Quarto scientific and technical publishing system. You might be asking why is it published and written like this even if it is not intended for any audiences except myself yet. I have no answer to this. One evening I simply decided to give Quarto publishing a try and set this whole thing up in less then an hour or so.\n\nNotes on writing\nThis note is written mostly for a future me, in case I need to set up the working environment again on a different machine and to serve as a memo if I forget how to continue.\nAs of November 2022, this is written on Archlabs GNU/Linux machine, mostly in Visual Studio Code editor and sometimes in RStudio. Changes are tracked with Git and a remote repository is on GitHub (see the note above), same as the rendered website. The rendered version of the manuscript is in the branch gh-pages. See a guide on how to set this up here. The online version is published with this command:\n\n\nTerminal\n\nquarto publish gh-pages\n\nIn my point of view, there are numerous advantages to scientific writing in this manner over traditional Office-based approach. A non-exhaustive list of why to do scientific writing this way is below.\n\nPlain text Writing in plain text enhanced with a simple Markdown syntax and some Quarto elements is great because from one source document, a .pdf, .html, .docx (and probably more) document formats can be rendered using pandoc.\nVersion control Tracking changes using git is easily implemented when writing in a plain text. Keeping track of any changes in the manuscript is obviously crucial for any later revisions etc.\nSimple citation management Bibliography is organized using Zotero with Better BibTeX extension which is used to export (and keep updated) necessary collections in a parent folder of the manuscript as .bib files. My Zotero library is here. To format the citations, a citation style of the Journal of Computer Applications in Archaeology is used (.csl file was obtained here).\nEmbedded code Code blocks (and the associated results) can be easily embedded in the text. My language of choice is R. For more information on reproducibility see Marwick (2017) and Marwick, Boettiger and Mullen (2018).\n\n\nMarwick, B. 2017 Computational Reproducibility in Archaeological Research: Basic Principles and a Case Study of Their Implementation. Journal of Archaeological Method and Theory 24(2): 424–450. DOI: https://doi.org/10.1007/s10816-015-9272-9.\n\nMarwick, B, Boettiger, C and Mullen, L. 2018 Packaging Data Analytical Work Reproducibly Using R (and Friends). The American Statistician 72(1): 80–88. DOI: https://doi.org/10.1080/00031305.2017.1375986.\n\n\n\n\n\n\nIn-text citations\n\n\n\n\n\n@citekey        -&gt; Author (year)\n-@citekey       -&gt; (year)\n[@citekey]      -&gt; (Author, year)\n@citekey [p. X] -&gt; Author (year, p. X)\n\n\n\n\n\n\n\n\n\nCrossrefs\n\n\n\n\n\n{#sec-label} -&gt; #sec-label\n{#fig-label} -&gt; #fig-label\ncrossref without numbering: -@sec-label, [Chapter -@sec-label]\n\n\n\n\n\nStats\nAs of August 18, 2023 there are roughly 19.2 pages of text. Length of individual chapters is as follows:\n\n\n     w     c                   f\n1  282  1896  chapters/intro.qmd\n2 3670 25391 chapters/theory.qmd\n3  229  1755 chapters/method.qmd\n4  810  5484   chapters/data.qmd\n5 4991 34526               total"
  },
  {
    "objectID": "chapters/intro.html#sec-context",
    "href": "chapters/intro.html#sec-context",
    "title": "Introduction",
    "section": "Context",
    "text": "Context\n\n\nArchaeological heritage management in the Czech Republic\nHow archaeology, its finds, sites and data are managed in various countries is heavily influenced by given legal framework. In this section, issues specific to the case of the Czech Republic are shortly described to give a basic context for the study."
  },
  {
    "objectID": "chapters/intro.html#sec-questions",
    "href": "chapters/intro.html#sec-questions",
    "title": "Introduction",
    "section": "Research questions",
    "text": "Research questions"
  },
  {
    "objectID": "chapters/intro.html#sec-outline",
    "href": "chapters/intro.html#sec-outline",
    "title": "Introduction",
    "section": "Thesis outline",
    "text": "Thesis outline\n\nHere is a brief outline of the structure of the thesis. In Chapter 1, Theory, the foundation is given by defining basic terms, data, data infrastructures etc. Then, theoretical approaches the work spans from are discussed and the concept of data in archaeology theorized. The dichotomy between archaeology as data- and/or theory-driven science is debated.\n\nChapter 2, Data, introduces data sources that are used here. Understanding the data models employed in various data sources is vital for any subsequent steps taken in the analytical process. Special attention is thus given to analysing how reality and facts are represented by the data models of used sources. A data management plan (Section 2.2) details how data is handled in this research."
  },
  {
    "objectID": "chapters/intro.html#summary",
    "href": "chapters/intro.html#summary",
    "title": "Introduction",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "chapters/theory.html#sec-terms",
    "href": "chapters/theory.html#sec-terms",
    "title": "1  Theory and method",
    "section": "1.1 Definitions and terminology",
    "text": "1.1 Definitions and terminology\nThis section presents a discussion of how I (and others) understand data and data infrastructures. Data are a corner stone of this work and looking closely at how scholars, policy makers, and various other stakeholders define them is crucial for further understanding what is possible and what is not in the process of knowledge building.\n\n1.1.1 Data\nIn the current information age, word data1 is almost omnipresent and it became such a generic term that it is somewhat challenging to define. Most of the definitions understand data as building blocks of information (e.g. Kitchin 2022: 4). These pieces of information are percieved as pre-factual and pre-analytical. That is, in contrast to facts, false data are data nonetheless, disproven facts are no longer facts (Rosenberg 2013: 17–18). Thus data are understood as incontrovertible and non-deconstructibe units. These assumptions migh lead to an impression that data exist in the outside world as entities or phenomena independent of the one observing them. And this is indeed one way to comprehend data, as ‘things given’ that just need to be discoverd (cf. Huggett 2020). This inductive explanation of data brings in itself a danger that the process of discovering the data is viewed as an atheoretical endeavour.1 In this text, I adhere to the current scholarly convention as noted by Kitchin (2022, xvii), i.e. using term data in the plural form, with a singular form of datum.\nKitchin, R. 2022. The data revolution: A critical analysis of big data, open data & data infrastructures. 2nd ed. Los Angeles, California: SAGE Publications.\n\nOn the contrary, data understood as ‘things made’ are created at the moment when they are captured by observation, measurement, or derived from other data. This implies theory-laden creative process of data generation, recording, etc. In this case, it is clear that the one creating or recording the data does that based on the experience, objective and knowledge he/she has. The whole process of data recording, creation, or capture is thus discursively framed and technically mediated (Huggett 2020; cf. Kitchin 2022: 4–15). As Kitchin notes, what we label as data are in fact capta, i.e. ‘things taken’.\n\nHuggett, J. 2020 Is Big Digital Data Different? Towards a New Archaeological Paradigm. Journal of Field Archaeology 45: S8–S17. DOI: https://doi.org/10.1080/00934690.2020.1713281.\n\nRuppert, E, Isin, E and Bigo, D. 2017 Data politics. Big Data & Society 4(2): 2053951717717749. DOI: https://doi.org/10.1177/2053951717717749.\nRuppert, Isin and Bigo (2017) voice the idea that the practice of data production does not happen through unstructured social (and/or political) practices, but through structured and structuring fields that add to configurations of power and knowledge. In this section we went from understanding data as ubiquitous phenomena that are waiting out there to be discovered to capta that are actively and creatively made, recorded, generated etc. by a theory- and agenda-laden researcher. What more, the practice of data production is recognized as being shaped by and contributing to structure of power and knowledge. What data are recorded and how they are structured has consequences as to what can be later devised, i.e. what knowlege can be generated.\n\nTalking about how chosen strategies in data recording and generation may influence the knowledge generated further along the way an idea of good and bad data might come to mind. Bad data, like false data, do not exist. Data can be useless, but their value is probably more determined by the current goal in mind. Nevertheless, there are some signs of good-quality data as cited2 by Kitchin (2022: 4):2 Author’s note: Kitchin cites Rosenberg (2013), but I was not able to locate this part in Rosenberg’s paper, which is primarily focused on the history of the term data in English language, not the quality of data.\nRosenberg, D. 2013 Data before the fact. In: Gitelman, L (ed.). ’Raw Data’ is an Oxymoron. Cambridge, MA: MIT Press. pp. 15–40.\n\n\nthey are discreet and intelligible, i.e. each datum is individual, separate and separable, and clearly defined;\nthey are aggregative, that is they can be built into sets;\nthey have associated metadata (data about data);\nthey can be linked to other datasets to provide insights not available from a single dataset.\n\n\n\n\n1.1.2 Infrastructures\nAlthough infrastructures became quite a buzzword in recent years both among the policy makers and researchers, it is rather difficult to define what an infrastructure actually is. Many slightly different variations of more-less the same name and concept are circulating in official documents, various reports, research articles etc. Thus, we encounter terms such as research infrastructures, large research infrastructures, open science infrastrucutres, data infrastructures, and perhaps more, even though most of their definitions are variations of the very same concept.\nHallonsten (2020) maps the field of European (research) infrastructures and identifies the principal problem as the difficulty to come up with a single definition that would fit all of those who are considered to be (or consider themselves to be) an infrastructure. Hallonsten (2020: 630) concludes that:\n\nHallonsten, O. 2020 Research Infrastructures in Europe: The Hype and the Field. European Review 28(4): 617–635. DOI: https://doi.org/10.1017/S1062798720000095.\n\n(…) “while a politically viable definition seems to be either already in place (…) or unneeded, an analytically workable definition is out of reach unless the scope is limited and the aim of the definition is made more precise.”\n\nIn the next paragraphs, we look at several of the political definitions of research infrastructures and later we focus on an analytical definition of data infrastructures.\n\nPolitical definitions\nIn the European Union, research infrastructures are currently defined in the Article 2(1) of EU Regulation No 2021/695 establishing Horizon Europe (2021) as facilities providing resources and services for the research communities in their respective fields. These include:\n\nAnon. 2021 Regulation (EU) 2021/695 of the European Parliament and of the Council. 32021R0695.\n\nhuman resources, major scientific equipment or sets of instruments;\ncollections, archives or scientific data, i.e. knowledge-related facilities;\ncomputing systems and communication networks;\nany other research and innovation infrastructure of a unique nature open to external users.\n\nThe Regulation also states that infrastructures may be used beyond research, i.e. for education, public services etc. This broad definition given by the European Union covers almost any kind of an infrastructure. In the legal framework of the Czech Republic, given by Act No 130/2002 Coll. on the Support of Research, Experimental Development and Innovation (2002), Article 2(2), large research infrastructure is defined as follow (english translation from Roadmap of Large Research Infrastructures 2019):\n\nAnon. 2002 Act No 130/2002 Coll. (The Act on the Support of Research, Experimental Development and Innovation), as amended.\n\nAnon. 2019. Roadmap of Large Research Infrastructures of the Czech Republic for the years 2016-2022. Update 2019. Prague: Ministry of Education, Youth and Sports.\n\n“(…) a facility necessary for conducting comprehensive research and development with high financial and technology demands, approved by the Government and established to be also used by other research organisations.”\n\nThis political definition is rather an opportunistic one in demanding that the infrastructure is approved by the Czech government and has high financial and technology demands. Lastly, the UNESCO Open Science Recommendation (2021) adds to the research infrastructures a strong element of open science, addressing them as open science infrastructures.\n\nUNESCO. 2021 UNESCO Recommendation on Open Science.\nTo conclude, the political definitions of research infrastructures are mostly broad enough to fit any kind of a facility, that is deemed appropriate. This point is highlighted especially in the Czech definition, where an approval of the Government is required. In general, there is an emphasis on provision of services (etc.) to various stakeholder communities and cooperation. In the EU Regulation, a subset of a larger field of infrastructures is labeled knowledge-related facilities, it is exactly this part that is discussed here as data infrastructures.\n\n\nData infrastructures\nKitchin (2022: 47–48) builds up the definition of data infrastructures by comparing them to data holdings and data archives. Data holdings are any data stored informally, presumably by an individual (scientist), without long-term preservation or sharing for reuse in mind. Such data are inevitably lost when the researcher retires, dies (etc.), because proper metadata descriptions are missing and the data, although they might be organised in some way, lack documentation and it is difficult, if not impossible, to reconstruct the context of the data. In contrast, data archives are formal collections that are structured, curated and documented by appropriate metadata with plans for preservation, access and discoverability.\nThe role of an interconnected digital world is then highlighted in Kitchin’s definition of a data infrastructure (Kitchin 2022: 50):\n\n“A data infrastructure is a digital means for storing, sharing, connecting and consuming data holdings and archives across the internet.”\n\nData infrastructures are thus information systems, repositories, archives, databases etc. shared by multiple shareholder groups that are essential in supporting open science and research."
  },
  {
    "objectID": "chapters/theory.html#sec-concepts",
    "href": "chapters/theory.html#sec-concepts",
    "title": "1  Theory and method",
    "section": "1.2 Overview of theoretical concepts",
    "text": "1.2 Overview of theoretical concepts\nThis section aims at briefly introducing theoretical approaches this work is shaped by. At first, digital humanities as an umbrella concept connecting the digital or computing world with the humanitites are introduced followed by discussion of digital, quantitative and computational archaeology. And lastly, spatial or landscape archaeology as a main concept framing this study is reviewed.\n\n1.2.1 Digital humanities\n\n\n1.2.2 Digital archaeology\n\n\n1.2.3 Computational and quantitative archaeology\n\n\n1.2.4 Spatial archaeology"
  },
  {
    "objectID": "chapters/theory.html#archaeology-as-theory--and-data-driven",
    "href": "chapters/theory.html#archaeology-as-theory--and-data-driven",
    "title": "1  Theory and method",
    "section": "1.3 Archaeology as theory- and data-driven",
    "text": "1.3 Archaeology as theory- and data-driven\n\n\n\n\n\n\nNote\n\n\n\nThis section is partly based on the Data-driven Archaeology. Are we there yet? talk co-authored with Hana Kubelková and Petr Květina presented at the Central European Theoretical Archaeology Group (CE TAG) meeting focused on Theoretical Approaches to Computational Archaeology I coorganized with Michael Kempf, Jan Kolář and Jiří Macháček in 2021 at the Department of Archaeology and Museology, Faculty of Arts, Masaryk University.\n\n\nIn his vision for the future of archaeology, Kristiansen (2014: 14) sees the opposition between theory and data disappear. Here we examine the percieved dichotomy between data- and theory-driven approaches. The idea that scientific method and/or theory is dead was addressed by many, but I will start this discussion with a trending comment by Anderson (2008).\n\nKristiansen, K. 2014 Towards a New Paradigm? The Third Science Revolution and its Possible Consequences in Archaeology. Current Swedish Archaeology 22(1): 11–34. DOI: https://doi.org/10.37718/CSA.2014.01.\n\nAnderson, C. 2008 The End of Theory: The Data Deluge Makes the Scientific Method Obsolete. Wired.\n\nBox, GEP. 1976 Science and Statistics. Journal of the American Statistical Association 71(356): 791–799. DOI: https://doi.org/10.1080/01621459.1976.10480949.\n\nBox, GEP. 1979 Robustness in the Strategy of Scientific Model Building. In: Launer, RL and Wilkinson, GN (eds.). Robustness in Statistics. Academic Press. pp. 201–236. DOI: https://doi.org/10.1016/B978-0-12-438150-6.50018-2.\nAnderson uses Boxes famous aphorism “(…) all models are wrong (…)” (Box 1976: 792), later extended to “All models are wrong but some [models] are useful.” (Box 1979: 202) and extends it to “All models are wrong, and increasingly you can succeed without them.” (Anderson 2008)."
  },
  {
    "objectID": "chapters/theory.html#theorizing-data",
    "href": "chapters/theory.html#theorizing-data",
    "title": "1  Theory and method",
    "section": "1.4 Theorizing data",
    "text": "1.4 Theorizing data\nDefining archaeological data, micro- to macro-scales;\nEarlier in this chapter it was explained that here, data is understood as capta, i.e. things, that are actively and creatively made, recorded, generated etc.\nIn this section we went from understanding data as ubiquitous phenomena that are waiting out there to be discovered to capta that are actively and creatively made, recorded, generated etc. by a theory- and agenda-laden researcher. What more, the practice of data production is recognized as being shaped by and contributing to structure of power and knowledge. What data are recorded and how they are structured has consequences as to what can be later devised, i.e. what knowlege can be generated."
  },
  {
    "objectID": "chapters/theory.html#sec-quality",
    "href": "chapters/theory.html#sec-quality",
    "title": "1  Theory and method",
    "section": "1.5 Assessing data infrastructures",
    "text": "1.5 Assessing data infrastructures\nIn this section I define a framework for an assessment of the quality of data infrastructures. As there are some signs of good-quality data (as cited from Kitchin (2022: 4) in the Section 1.1.1), i.e. they are discreet and intelligible, aggregative, have associated metadata and can be linked to other datasets, by extension, good-quality data infrastructures allow data to be discreet and separable from other data, enable data aggregation, contain metadata and allow linking to other data sources. This gives us a general idea about requirements for a data infrastrucutre, but is difficult to assess in practice. These general ideas are concretized and further developed by the FAIR data principles (Wilkinson et al. 2016), which are aimed at enhancing the reusability of data holdings with an emphasis on the ability of machines to find and use the data. The FAIR data principles are measurable what gives us an opportunity to assess how FAIR an infrastructure is.\n\nFAIR data principles, i.e. findability, accessibility, interoperability and reusability, as originally defined by Wilkinson et al. (2016: 4), are as follows. To be findable, data and metadata have globally unique and persistent identifiers; are described with rich metadata which include the identifier of the data they describe; and are registered or indexed in a searchable resource. To be accessible, (meta)data are retrievable by the identifier using a standardized (open, free and universally implementable) communications protocol that allows for an authentication and authorization procedure; and metadata are accessible, even when the data are no longer available. To be interoperable, (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation; contain vocabularies that follow FAIR principles; and include qualified references to other (meta)data. To be reusable, meta(data) are richly described with a plurality of accurate and relevant attributes; are released with a clear and accessible data usage license; are associated with detailed provenance; and meet domain-relevant community standards.\n\n\nWith archaeology audiences in mind, the principles are further explained together with tips for implementations etc. by Hollander et al. (2019). Here I build up on Wilkinson et al. (2016) and Hollander et al. (2019) to come up with a set of formal, i.e. measurable and/or determinable criteria for assessment of data infrastructures. This framework is then used to evaluate archaeology data infrastructures in the Czech Republic in Chapter 2.\n\nHollander, H, Morselli, F, Uiterwaal, F, Admiraal, F, Trippel, T and Giorgio, SD. 2019 PARTHENOS Guidelines to FAIRify data management and make data reusable DOI: https://doi.org/10.5281/zenodo.2668478.\n\nWilkinson, MD, Dumontier, M, Aalbersberg, IjJ, Appleton, G, Axton, M, Baak, A, Blomberg, N, Boiten, J-W, da Silva Santos, LB, Bourne, PE, Bouwman, J, Brookes, AJ, Clark, T, Crosas, M, Dillo, I, Dumon, O, Edmunds, S, Evelo, CT, Finkers, R, Gonzalez-Beltran, A, Gray, AJG, Groth, P, Goble, C, Grethe, JS, Heringa, J, ’t Hoen, PAC, Hooft, R, Kuhn, T, Kok, R, Kok, J, Lusher, SJ, Martone, ME, Mons, A, Packer, AL, Persson, B, Rocca-Serra, P, Roos, M, van Schaik, R, Sansone, S-A, Schultes, E, Sengstag, T, Slater, T, Strawn, G, Swertz, MA, Thompson, M, van der Lei, J, van Mulligen, E, Velterop, J, Waagmeester, A, Wittenburg, P, Wolstencroft, K, Zhao, J and Mons, B. 2016 The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data 3(160018): DOI: https://doi.org/10.1038/sdata.2016.18.\n\n1.5.1 Assessment framework\nAssessment criteria are grouped together according to the FAIR principle they relate to. Table 1.1 lists criteria for findability of resources. Data should be easy to find by both humans and machines and well documented by metadata in order to be reusable by other researchers. To be able to use the data object in any way, it must be possible to uniquely identify it, find it, and refer to it (F1). This implies that an identifier of some sort, preferably persistent, i.e. immutable and long-lasting, is assigned to the resource (data and/or metadata). Persistent identifiers typically take form of DOIs, Handles, PURLs and URNs to name just a few examples3.3 Handles and DOIs (Digital Object Identifiers) are composed of a prefix/suffix and typically resolved at https://doi.org/. URNs (Uniform Resource Names), in form urn:namespace:name, are mostly used in the Semantic Web and are not resolvable, i.e. URNs do not have information about the location of the object. PURLs (Persistent Uniform Resource Locators) are an extension of URLs and are resolvable. URNs and (P)URLs are both subsets of URIs (Uniform Resource Identifiers). See e.g. DuCharme (2013: 21–23) for details.\nDuCharme, B. 2013. Learning SPARQL: Querying and updating with SPARQL 1.1. Second edition. Sebastopol, CA: O’Reilly Media.\n\nFurthermore, it is convenient to be able to locate the resource (preferably on the internet) if the identifier, and possibly prefix of some sort, is known (F2). Since Marwick and Birch (2018) explore the lack of data citation and reuse in archaeology and suggest a standard for data citation, one of the criteria is whether the infrastructure makes it easy to cite the resources it publishes (F3). Another feature that enables findability of data is a rich metadata description (F4–F5).\n\nMarwick, B and Birch, SEP. 2018 A Standard for the Scholarly Citation of Archaeological Data as an Incentive to Data Sharing. Advances in Archaeological Practice 6(2): 125–143. DOI: https://doi.org/10.1017/aap.2018.3.\n\n\n\n\nTable 1.1: Framework for quality assessment of data infrastrastructres – Findability\n\n\n\n\n\n\n\nID\nFindability\nValue\n\n\n\n\nF1.1\nAre there unique identifiers?\nTrue/False\n\n\nF1.2\nAre the identifiers persistent?\nTrue/False\n\n\nF1.3\nAre the identifiers in any standard form?\nTrue/False\n\n\nF2\nIs it possible to locate the resource by the identifier?\nTrue/False\n\n\nF3\nIs it possible (and made easy) to cite:\n-\n\n\nF3.1\n- the data infrastructure,\nTrue/False\n\n\nF3.2\n- its parts and/or\nTrue/False\n\n\nF3.3\n- individual resources?\nTrue/False\n\n\nF4.1\nIs the metadata scheme described, i.e. explicit?\nTrue/False\n\n\nF4.2\nDoes the metadata scheme follow a standard?\nTrue/False\n\n\nF5\nAre the metadata searchable?\nTrue/False\n\n\n\n\n\n\nCriteria for accessibility are listed in Table 1.2. Accessible data are retrievable under well-defined conditions using standardised protocols. Certification of a data infrastructure guarantees that its repository is trustworthy, the data are stored safely and will be available over a long period of time. Certifications may include CoreTrustSeal, nestor seal etc. (A1). By a standardised exchange protocol (A2.1) a well-documented technology created and maintained by a recognized authority (e.g. World Wide Web Consortium, W3C) is meant. For example SPARQL is a query language for semantic data created by W3C, OAI-PMH, a Protocol for Metadata Harvesting, is created and maintained by the Open Archives Initiative etc. By a standardised format (A2.2) a machine-readable format is meant, for instance XML, a W3C format for hierarchical data representation, RDF, a W3C standard for semantic data, etc.\nFor (meta)data to be easily accessible, the policies for the access need to be clearly stated (A3), i.e. definitions of who can access what and when needs to be explicitly communicated, for example existence of differentiated user roles and/or embargo periods. This gives both the users accessing the data clear instructions on how to access the objects they need, and the users depositing the data sets options to protect sensitive data etc. Existence of policies how to handle situations if a data object is no longer available (e.g. deleted, superseded etc.) and presence of metadata tombstones is a good practice how to communicate that a data object existed, but does not anymore (A4).\n\n\n\n\nTable 1.2: Framework for quality assessment of data infrastrastructres – Accessibility\n\n\n\n\n\n\n\nID\nAccessibility\nValue\n\n\n\n\nA1\nIs the repository trustworthy?\nTrue/False\n\n\nA2.1\nAre the (meta)data retrievable using a standardised protocol?\nTrue/False\n\n\nA2.2\nAre the metadata in a standardised format?\nTrue/False\n\n\nA3\nIs the access policy clearly stated?\nTrue/False\n\n\nA3.1\nAre there embargo periods?\nTrue/False\n\n\nA3.2\nAre the access rights differentiated?\nTrue/False\n\n\nA4\nIs the metadata available even after the data is not?\nTrue/False\n\n\n\n\n\n\nInteroperability is the ability of the (meta)data to be easily combined with other data sets, Table 1.3 lists the interoperability criteria relevant to data infrastructures. Machine interoperability is closely related to the availability of APIs and their quality and human interoperability derives from the existence and extensiveness of documentation.\nTo enable interoperability, (meta)data model4 needs to be described clearly and accessibly (I1) and employed controlled vocabularies need to be explained and published, preferably following the FAIR principles (I2). Explanation of the given data model and vocabularies describing exact meanings embedded in the data are a prerequisites for building understanding by other people. Furthermore, well-documented (meta)data models allow creation of mappings between different metadata schemes and data infrastructures. Similarly, the existence of machine actionable APIs (application programming interfaces, I4) that allow harvesting of (meta)data through standardised protocols and return responses in standardised formats (cf. A2) ensure machine interoperability.4 The term data model is used here in the sense of how phenomena present, observed and/or measured in the real world are encoded in the data, what ratinale is behind the chosen abstraction process, and what is actually meant by the given wording.\n\n\n\n\nTable 1.3: Framework for quality assessment of data infrastrastructres – Interoperability\n\n\nID\nInteroperability\nValue\n\n\n\n\nI1\nIs the (meta)data model explained and documented?\nTrue/False\n\n\nI2.1\nAre the vocabularies published and/or well-known?\nTrue/False\n\n\nI2.2\nAre the vocabularies FAIR?\nTrue/False\n\n\nI3\nAre other metadata referenced properly?\nTrue/False\n\n\nI4.1\nIs there a machine-actionable API?\nTrue/False\n\n\nI4.2\nIs the API well documented?\nTrue/False\n\n\n\n\n\n\nBy reusability the process of making data ready for future processing and analysis is meant. This is crucial for reproducibility of scientific research. Data, repositories and infrastructures that are systematically documented by manuals, tutorials, guides, codebooks etc. and transparent about what they do and do not contain foster reuse, because researchers reusing the data have clear notion of what to expect from the data source (R1). Reusability is also enhanced by using widely used and open source file formats (R2). In the long run, long-term preservation (LTP) is a prerequisite for reusability, because if the file format in which the data is saved gets obsolete, it is often difficult to retrieve the original data, see Brin et al. (2013) for recommended file formats, online as Guides to Good Practice (n.d.).\n\nBrin, A, McManamon, FP, Niven, K, Archaeology Data Service and Digital Antiquity (eds.). 2013. Caring for digital data in archaeology: A guide to good practice. Archaeology Data Service and Digital Antiquity. Oxford ; Oakville: Oxbow Books.\n\nArchaeology Data Service and Digital Antiquity. n.d. Guides to Good Practice. Available at https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/ [Last accessed August 18, 2023].\nIntegrity of the (meta)data and existence of multiple versions of the given data objects is also important to consider, because if this information is not properly communicated, different versions of the data objects with identical identifiers might get mixed up (R3). This closely relates to the provenance of the data, i.e. the documentation of the origin of the data object and record of any changes with a rationale behind these processes. Knowing why changes in the (meta)data happened, whether it was a correction of a previous mistake or something else, might be useful for data reuse in the future. Lastly, releasing the (meta)data with proper license information, preferably under a standard data license, for instance a Creative Commons Licence, and any information on a rights holder is neccessary for future reuse because without this information, it is unclear what the terms of (meta)data use are.\n\n\n\n\nTable 1.4: Framework for quality assessment of data infrastrastructres – Reusability\n\n\n\n\n\n\n\nID\nReusability\nValue\n\n\n\n\nR1\nAre there documentation, manuals, tutorials etc?\nTrue/False\n\n\nR2.1\nAre common file formats used?\nTrue/False\n\n\nR2.2\nAre file formats suitable for long-term preservation?\nTrue/False\n\n\nR3.1\nIs the (meta)data provenance documented?\nTrue/False\n\n\nR3.2\nAre there any version control mechanisms in place?\nTrue/False\n\n\nR4.1\nAre the rights holders and terms of use clear?\nTrue/False\n\n\nR4.2\nAre the resources released under a standard license?\nTrue/False\n\n\n\n\n\n\nThe framework consists predominantly of qualities that are measurable and builds up on the FAIR data principles. CARE data principles, as defined by Carroll et al. (2020), were considered as well, but their goal is to increase the indigenous data sovereignity and self-determination by being people and purpose-oriented, while the FAIR data principles are primarily focused on the characteristics of the data. CARE data principles are put together to address imbalances of power in the knowledge societies and economies and protect indigenous and human rights. Hence the extent to which a data infrastructure adheres to CARE data principles is difficult to determine and/or measure.\n\nCarroll, SR, Garba, I, Figueroa-Rodríguez, OL, Holbrook, J, Lovett, R, Materechera, S, Parsons, M, Raseroka, K, Rodriguez-Lonebear, D, Rowe, R, Sara, R, Walker, JD, Anderson, J and Hudson, M. 2020 The CARE Principles for Indigenous Data Governance. Data Science Journal 19: 43. DOI: https://doi.org/10.5334/dsj-2020-043.\nThe framework for assessment of the quality of data infrastructures is used in Chapter 2 to evaluate the quality of archaeology data infrastructures in the Czech Republic."
  },
  {
    "objectID": "chapters/theory.html#software",
    "href": "chapters/theory.html#software",
    "title": "1  Theory and method",
    "section": "1.6 Software",
    "text": "1.6 Software\nMost of the things included here, if not all of them, were achieved using open-source software. Large part of this endeavor is also documented in code. This text was written in plain text with some basic markdown and quarto syntax for formatting, cross references, citations etc. At some places there are R code blocks. The text is processed into three outputs, a website (HTML document), a PDF document and a MS Word document using Quarto. The plain text version, same as the rendered website, is hosted at GitHub. The text was mostly written in the Visual Code Studio, analysis were mostly performed using Rstudio or terminal. Library was organized using Zotero.\nRaster graphics were created and edited using GIMP, vector graphics using Inkscape. All the GIS operations that required graphical user interface (GUI), or were more conveniently performed in a GUI, were done in QGIS.\nSome data were prepared, extracted or processed using basic GNU/Linux shell or SQL commands or scripts. Data from Wikidata was queried using SPARQL. Any analysis was mostly done in R, a language for statistical computing and graphics (R Core Team 2023). Various packages were used, the most important packages are listed here, the complete list is in an Appendix\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing.\n\n1.6.1 Reproduciblity"
  },
  {
    "objectID": "chapters/theory.html#chapter-summary",
    "href": "chapters/theory.html#chapter-summary",
    "title": "1  Theory and method",
    "section": "Chapter summary",
    "text": "Chapter summary"
  },
  {
    "objectID": "chapters/data.html#sec-sources",
    "href": "chapters/data.html#sec-sources",
    "title": "2  Data and materials",
    "section": "2.1 Sources of archaeology data in the Czech Republic",
    "text": "2.1 Sources of archaeology data in the Czech Republic\n\n2.1.1 Archaeology information system of the Czech Republic\n\n\n2.1.2 Legacy data sources\nWhat is a legacy data source?\n\nMuseum databases"
  },
  {
    "objectID": "chapters/data.html#sec-dmp",
    "href": "chapters/data.html#sec-dmp",
    "title": "2  Data and materials",
    "section": "2.2 Data management plan",
    "text": "2.2 Data management plan\nGood data stewardship is a crucial element in Open Science (Mons 2018: 1–5), an umbrella concept for how scientific research is conducted in a way that knowledge is reusable, modifiable and redistributable. The data management plan (DMP) then stands at the very beginning of every such endeavour. In its essence, a DMP is a stand-alone document detailing how data is handled at each of the steps in its life cycle. This implies that it is not a static, but a living record of how the data was captured, created, curated, selected, analysed, interpreted, shared, and archived in course of a project or after its end. A DMP helps in adhering to the FAIR principles, i.e. making data findable, accessible, interoperable and reusable, a set of propositions enabling more effective knowledge discovery, collaboration, and data reuse (Hollander et al. 2019; Wilkinson et al. 2016).\n\nMons, B. 2018. Data Stewardship For Open Science: Implementing FAIR principles. Boca Raton: CRC Press, Taylor & Francis Group.\n\nHollander, H, Morselli, F, Uiterwaal, F, Admiraal, F, Trippel, T and Giorgio, SD. 2019 PARTHENOS Guidelines to FAIRify data management and make data reusable DOI: https://doi.org/10.5281/zenodo.2668478.\n\nWilkinson, MD, Dumontier, M, Aalbersberg, IjJ, Appleton, G, Axton, M, Baak, A, Blomberg, N, Boiten, J-W, da Silva Santos, LB, Bourne, PE, Bouwman, J, Brookes, AJ, Clark, T, Crosas, M, Dillo, I, Dumon, O, Edmunds, S, Evelo, CT, Finkers, R, Gonzalez-Beltran, A, Gray, AJG, Groth, P, Goble, C, Grethe, JS, Heringa, J, ’t Hoen, PAC, Hooft, R, Kuhn, T, Kok, R, Kok, J, Lusher, SJ, Martone, ME, Mons, A, Packer, AL, Persson, B, Rocca-Serra, P, Roos, M, van Schaik, R, Sansone, S-A, Schultes, E, Sengstag, T, Slater, T, Strawn, G, Swertz, MA, Thompson, M, van der Lei, J, van Mulligen, E, Velterop, J, Waagmeester, A, Wittenburg, P, Wolstencroft, K, Zhao, J and Mons, B. 2016 The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data 3(160018): DOI: https://doi.org/10.1038/sdata.2016.18.\n\nPergl, R, Hooft, R, Suchánek, M, Knaisl, V and Slifka, J. 2019 “Data Stewardship Wizard”: A Tool Bringing Together Researchers, Data Stewards, and Data Experts around Data Management Planning. Data Science Journal 18(1, 1): 59. DOI: https://doi.org/10.5334/dsj-2019-059.\n\nDoorn, P and Ronzino, P. 2022. ARIADNEplus Data Management Plan Tools. 25 March 2022. Available at https://vast-lab.org/dmp/ [Last accessed November 17, 2022].\nThis DMP is partly based on the structure given in the Data Stewardship Wizard (Pergl et al. 2019), an online tool dedicated to cooperative creation of DMPs, templates created in the Ariadne project (Doorn and Ronzino 2022) and my own ideas on good DMP practice. It is included both as part of the text and as a standalone machine actionable file (link?). \n\n2.2.1 Created, collected and re-used data\n\nData re-use\nThe work is predominantly based on re-using existing data. The sources of data are listed in Section 2.1. I presume that there are many pre-existing data sets in the Czech archaeology, but most of them are either inaccessible or not findable, i.e. we cannot be sure they even exist. The single most complete source for archaeology data in the Czech Republic is without a doubt the AIS CR infrastructure.\nThere are several well published data sets covering the area of the Czech Republic in the Journal of Open Archaeology Data, the radiocarbon data by Tkáč and Kolář (2021) and the Neolithic settlements data set by Pajdla and Trampota (2021). These have an advantage of well formulated access and re-use policies, explicit licence and other conditions for use.\n\n\nTkáč, P and Kolář, J. 2021 Towards New Demography Proxies and Regional Chronologies: Radiocarbon Dates from Archaeological Contexts Located in the Czech Republic Covering the Period Between 10,000 BC and AD 1250. Journal of Open Archaeology Data 9(0, 0): 9. DOI: https://doi.org/10.5334/joad.85.\n\nPajdla, P and Trampota, F. 2021 Neolithic Settlements in Central Europe: Data from the Project “Lifestyle as an Unintentional Identity in the Neolithic.” Journal of Open Archaeology Data 9(0, 0): 13. DOI: https://doi.org/10.5334/joad.88.\n\n\nData creation and collection\n\n\n\n\nVocabularies\n\nI am explicitly using vocabularies that are inherent to data sources from which the data is reused. A principal and authoritative vocabulary for archaeology and related fields is the Getty Art & Architecture Thesaurus (AAT). Getty AAT subjects are used by the ARIADNE infrastructure and many other archaeology infrastructures are mapping their vocabularies to the AAT subjects. The emerging ARIADNE AO_Cat formal ontology is also taken into account when interacting with ARIADNE services. The AIS CR vocabularies, although implicit to the data, are yet to be published. A possibly incomplete version can be reverse engineered from the available data sets. If reconciliation between data from different data sources is necessary, the AAT is used to map between them.\n\n\n\nFile naming conventions\nPersistent identifiers?\n\n\n\n2.2.2 Data processing\nHow will you work with the data? Do you have/need storage? Do you do backups? Are you using object-store? Are you using relational database? Graph database? Triple store? How are changes in data managed?\n\n\n2.2.3 Interpretation\nSpecify/list data formats you will be using and their structure. Will different data be integrated?\n\n\n2.2.4 Data preservation\nWhat data sets are you producing? Is data long-term archived? Will it be usable and accessible after a long period of time?\n\n\n2.2.5 Access to data\nWill the data be as open as possible? What are the reasons your data cannot became open?"
  },
  {
    "objectID": "chapters/data.html#chapter-summary",
    "href": "chapters/data.html#chapter-summary",
    "title": "2  Data and materials",
    "section": "Chapter summary",
    "text": "Chapter summary"
  },
  {
    "objectID": "biblio/references.html",
    "href": "biblio/references.html",
    "title": "References",
    "section": "",
    "text": "Anderson, C. 2008 The\nEnd of Theory: The Data Deluge\nMakes the Scientific Method Obsolete.\nWired.\n\n\nAnon. 2002 Act No 130/2002 Coll. (The\nAct on the Support of Research,\nExperimental Development and Innovation), as\namended.\n\n\nAnon. 2019. Roadmap\nof Large Research Infrastructures of the Czech\nRepublic for the years 2016-2022. Update 2019.\nPrague: Ministry of Education, Youth and\nSports.\n\n\nAnon. 2021 Regulation\n(EU) 2021/695 of the European Parliament and\nof the Council. 32021R0695.\n\n\nArchaeology Data Service and Digital Antiquity. n.d. Guides to\nGood Practice. Available at https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/\n[Last accessed 18 August 2023].\n\n\nBox, GEP. 1976 Science and Statistics. Journal of the\nAmerican Statistical Association 71(356): 791–799. DOI:\nhttps://doi.org/10.1080/01621459.1976.10480949.\n\n\nBox, GEP. 1979 Robustness in the Strategy of\nScientific Model Building. In: Launer, RL and Wilkinson, GN\n(eds.). Robustness in Statistics. Academic\nPress. pp. 201–236. DOI: https://doi.org/10.1016/B978-0-12-438150-6.50018-2.\n\n\nBrin, A, McManamon, FP, Niven, K, Archaeology Data Service and Digital\nAntiquity (eds.). 2013. Caring for digital data in archaeology:\nA guide to good practice. Archaeology Data\nService and Digital Antiquity. Oxford ;\nOakville: Oxbow Books.\n\n\nCarroll, SR, Garba, I, Figueroa-Rodríguez, OL, Holbrook, J, Lovett, R,\nMaterechera, S, Parsons, M, Raseroka, K, Rodriguez-Lonebear, D, Rowe, R,\nSara, R, Walker, JD, Anderson, J and Hudson, M. 2020 The CARE\nPrinciples for Indigenous Data Governance. Data\nScience Journal 19: 43. DOI: https://doi.org/10.5334/dsj-2020-043.\n\n\nDoorn, P and Ronzino, P. 2022. ARIADNEplus Data Management\nPlan Tools. 25 March 2022. Available at https://vast-lab.org/dmp/ [Last\naccessed 17 November 2022].\n\n\nDuCharme, B. 2013. Learning SPARQL: Querying and\nupdating with SPARQL 1.1. Second edition.\nSebastopol, CA: O’Reilly Media.\n\n\nHallonsten, O. 2020 Research Infrastructures in\nEurope: The Hype and the Field.\nEuropean Review 28(4): 617–635. DOI: https://doi.org/10.1017/S1062798720000095.\n\n\nHollander, H, Morselli, F, Uiterwaal, F, Admiraal, F, Trippel, T and\nGiorgio, SD. 2019 PARTHENOS Guidelines to\nFAIRify data management and make data reusable DOI:\nhttps://doi.org/10.5281/zenodo.2668478.\n\n\nHuggett, J. 2020 Is Big Digital Data Different?\nTowards a New Archaeological Paradigm.\nJournal of Field Archaeology 45: S8–S17. DOI:\nhttps://doi.org/10.1080/00934690.2020.1713281.\n\n\nKitchin, R. 2022. The data revolution: A critical\nanalysis of big data, open data & data infrastructures. 2nd ed.\nLos Angeles, California: SAGE Publications.\n\n\nKristiansen, K. 2014 Towards a New Paradigm? The\nThird Science Revolution and its Possible\nConsequences in Archaeology. Current Swedish\nArchaeology 22(1): 11–34. DOI: https://doi.org/10.37718/CSA.2014.01.\n\n\nMarwick, B. 2017 Computational Reproducibility in\nArchaeological Research: Basic Principles and\na Case Study of Their Implementation.\nJournal of Archaeological Method and Theory 24(2): 424–450.\nDOI: https://doi.org/10.1007/s10816-015-9272-9.\n\n\nMarwick, B and Birch, SEP. 2018 A Standard for the\nScholarly Citation of Archaeological Data as\nan Incentive to Data Sharing. Advances in\nArchaeological Practice 6(2): 125–143. DOI: https://doi.org/10.1017/aap.2018.3.\n\n\nMarwick, B, Boettiger, C and Mullen, L. 2018 Packaging Data\nAnalytical Work Reproducibly Using R (and Friends).\nThe American Statistician 72(1): 80–88. DOI: https://doi.org/10.1080/00031305.2017.1375986.\n\n\nMons, B. 2018. Data Stewardship For Open Science:\nImplementing FAIR principles. Boca Raton:\nCRC Press, Taylor & Francis Group.\n\n\nPajdla, P and Trampota, F. 2021 Neolithic Settlements in\nCentral Europe: Data from the\nProject ‘Lifestyle as an\nUnintentional Identity in the\nNeolithic’. Journal of Open Archaeology\nData 9(0, 0): 13. DOI: https://doi.org/10.5334/joad.88.\n\n\nPergl, R, Hooft, R, Suchánek, M, Knaisl, V and Slifka, J. 2019\n‘Data Stewardship Wizard’: A Tool\nBringing Together Researchers, Data Stewards, and\nData Experts around Data Management Planning.\nData Science Journal 18(1, 1): 59. DOI: https://doi.org/10.5334/dsj-2019-059.\n\n\nR Core Team. 2023. R: A\nLanguage and Environment for Statistical\nComputing. Vienna, Austria: R\nFoundation for Statistical Computing.\n\n\nRosenberg, D. 2013 Data before the fact. In: Gitelman, L (ed.).\n’Raw Data’ is an Oxymoron.\nCambridge, MA: MIT Press. pp. 15–40.\n\n\nRuppert, E, Isin, E and Bigo, D. 2017 Data politics. Big Data &\nSociety 4(2): 2053951717717749. DOI: https://doi.org/10.1177/2053951717717749.\n\n\nTkáč, P and Kolář, J. 2021 Towards New Demography Proxies\nand Regional Chronologies: Radiocarbon Dates\nfrom Archaeological Contexts Located in the Czech\nRepublic Covering the Period Between 10,000\nBC and AD 1250. Journal of Open\nArchaeology Data 9(0, 0): 9. DOI: https://doi.org/10.5334/joad.85.\n\n\nUNESCO. 2021 UNESCO\nRecommendation on Open Science.\n\n\nWilkinson, MD, Dumontier, M, Aalbersberg, IjJ, Appleton, G, Axton, M,\nBaak, A, Blomberg, N, Boiten, J-W, da Silva Santos, LB, Bourne, PE,\nBouwman, J, Brookes, AJ, Clark, T, Crosas, M, Dillo, I, Dumon, O,\nEdmunds, S, Evelo, CT, Finkers, R, Gonzalez-Beltran, A, Gray, AJG,\nGroth, P, Goble, C, Grethe, JS, Heringa, J, ’t Hoen, PAC, Hooft, R,\nKuhn, T, Kok, R, Kok, J, Lusher, SJ, Martone, ME, Mons, A, Packer, AL,\nPersson, B, Rocca-Serra, P, Roos, M, van Schaik, R, Sansone, S-A,\nSchultes, E, Sengstag, T, Slater, T, Strawn, G, Swertz, MA, Thompson, M,\nvan der Lei, J, van Mulligen, E, Velterop, J, Waagmeester, A,\nWittenburg, P, Wolstencroft, K, Zhao, J and Mons, B. 2016 The FAIR\nGuiding Principles for scientific data management and\nstewardship. Scientific Data 3(160018): DOI: https://doi.org/10.1038/sdata.2016.18."
  }
]